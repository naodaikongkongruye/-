{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd671e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import catboost as cbt\n",
    "from sklearn.svm import SVC\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, log_loss\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "#from sklearn.ensemble import CatBoostClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import gc\n",
    "import math\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import datetime\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = None\n",
    "\n",
    "#解决matplotlib绘图中文显示问题\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']\n",
    "# plt.rcParams['font.sans-serif'] = ['KaiTi']   # 指定默认字体\n",
    "plt.rcParams['axes.unicode_minus'] = False   # 解决保存图像是负号'-'显示为方块的问题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad16e24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(r'E:\\Study\\机器学习\\wb\\first_round_training_data.csv')\n",
    "test = pd.read_csv(r'E:\\Study\\机器学习\\wb\\first_round_testing_data.csv')\n",
    "\n",
    "start_index = 1\n",
    "end_index = 11\n",
    "\n",
    "submit = pd.read_csv(r'E:\\Study\\机器学习\\wb\\submit_example.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bcfef742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Parameter1    Parameter2     Parameter3     Parameter4  \\\n",
      "count    6000.000000  6.000000e+03    6000.000000    6000.000000   \n",
      "mean      485.198954  1.952379e+03     406.348529     189.205842   \n",
      "std     11401.971393  5.419588e+04   12018.898941    2621.779049   \n",
      "min         0.000003  1.683797e-07       0.000005       0.000002   \n",
      "25%         0.088221  4.765771e-02       0.102304       0.118314   \n",
      "50%         1.050304  9.405962e-01       1.044908       1.068467   \n",
      "75%        10.938565  1.569199e+01      10.665397       9.902064   \n",
      "max    713682.207601  3.034568e+06  864530.632179  139767.494732   \n",
      "\n",
      "         Parameter5    Parameter6    Parameter7    Parameter8    Parameter9  \\\n",
      "count  6.000000e+03  6.000000e+03   6000.000000   6000.000000  6.000000e+03   \n",
      "mean   5.868163e+00  5.598597e+00    272.300821     22.133231  5.823664e+04   \n",
      "std    8.631865e+00  7.686898e+00   2027.460514    302.172768  3.173068e+06   \n",
      "min    9.985942e-07  9.810610e-07      0.000624      0.023699  3.962831e-04   \n",
      "25%    7.416296e-01  3.818154e-01      0.152059      0.035407  5.930812e-01   \n",
      "50%    2.225808e+00  2.684398e+00      0.600827      2.931083  5.930812e-01   \n",
      "75%    6.680183e+00  7.117767e+00      2.374035     17.850021  6.783967e+00   \n",
      "max    8.367195e+01  4.117541e+01  35698.591553  20086.397753  1.738083e+08   \n",
      "\n",
      "       Parameter10    Attribute1    Attribute2     Attribute3    Attribute4  \\\n",
      "count  6000.000000  6.000000e+03  6.000000e+03    6000.000000  6.000000e+03   \n",
      "mean     35.902066  5.351032e+04  8.842895e+04     202.732522  6.271156e+03   \n",
      "std     101.629348  1.894866e+06  2.854543e+06    2754.503943  2.585508e+05   \n",
      "min       0.001024  6.457597e-10  5.493777e-09       0.000001  4.344229e-06   \n",
      "25%       0.101478  3.100601e-02  3.173294e-02       0.098178  1.319373e-01   \n",
      "50%       0.727611  9.449563e-01  1.030499e+00       0.945947  8.297855e-01   \n",
      "75%      13.969790  2.784766e+01  3.001000e+01       9.803828  6.052952e+00   \n",
      "max     517.197610  1.197060e+08  1.615907e+08  128491.084741  1.572225e+07   \n",
      "\n",
      "         Attribute5    Attribute6    Attribute7    Attribute8    Attribute9  \\\n",
      "count  6.000000e+03  6.000000e+03  6.000000e+03  6.000000e+03  6.000000e+03   \n",
      "mean   1.285985e+06  3.400877e+03  3.166863e+04  4.545394e+05  7.860735e+05   \n",
      "std    9.850723e+07  1.999508e+05  1.116889e+06  2.847995e+07  5.885757e+07   \n",
      "min    1.635864e-06  5.456653e-05  4.411611e-03  3.011145e-03  2.366726e-03   \n",
      "25%    1.150362e-01  1.443224e-01  1.135895e-01  1.115708e-01  1.267717e-01   \n",
      "50%    7.539155e-01  9.864325e-01  5.891701e-01  5.922906e-01  6.644951e-01   \n",
      "75%    5.736029e+00  7.422284e+00  4.637157e+00  4.773050e+00  5.571728e+00   \n",
      "max    7.630284e+09  1.488592e+07  7.789923e+07  2.187522e+09  4.558485e+09   \n",
      "\n",
      "        Attribute10  \n",
      "count  6.000000e+03  \n",
      "mean   1.989520e+07  \n",
      "std    1.529785e+09  \n",
      "min    1.974795e-03  \n",
      "25%    1.253268e-01  \n",
      "50%    6.705953e-01  \n",
      "75%    4.905501e+00  \n",
      "max    1.184961e+11  \n"
     ]
    }
   ],
   "source": [
    "print(train.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d24a775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Group    Parameter1  Parameter10     Parameter2    Parameter3  \\\n",
      "count  6000.0000  6.000000e+03  6000.000000    6000.000000  6.000000e+03   \n",
      "mean     59.5000  1.072897e+05    26.514627     369.101132  1.132272e+03   \n",
      "std      34.6427  2.980241e+06    84.807106    6352.033456  3.220140e+04   \n",
      "min       0.0000  1.331475e-09     0.001024       0.000001  5.436324e-08   \n",
      "25%      29.7500  2.233015e-02     0.101478       0.090422  6.985572e-02   \n",
      "50%      59.5000  8.489791e-01     0.727611       1.000019  8.985648e-01   \n",
      "75%      89.2500  3.103161e+01    10.060093      12.159195  1.300345e+01   \n",
      "max     119.0000  1.758842e+08   517.197610  317368.685606  2.183219e+06   \n",
      "\n",
      "         Parameter4   Parameter5   Parameter6    Parameter7    Parameter8  \\\n",
      "count  6.000000e+03  6000.000000  6000.000000   6000.000000   6000.000000   \n",
      "mean   2.196607e+07     5.019799     5.404172    210.884571     59.810770   \n",
      "std    1.429351e+09     6.782677     6.788654   1616.938611   1545.270888   \n",
      "min    4.859234e-10     0.000003     0.000005      0.000624      0.023699   \n",
      "25%    1.867368e-02     0.827784     0.563965      0.152059      0.035407   \n",
      "50%    1.002728e+00     2.772987     2.684398      0.600827      2.931083   \n",
      "75%    5.193707e+01     6.680183     7.117767      2.374035     17.850021   \n",
      "max    1.101618e+11    83.671947    41.175410  35698.591553  66984.723637   \n",
      "\n",
      "         Parameter9  \n",
      "count  6.000000e+03  \n",
      "mean   8.764239e+04  \n",
      "std    3.885921e+06  \n",
      "min    3.962831e-04  \n",
      "25%    5.930812e-01  \n",
      "50%    5.930812e-01  \n",
      "75%    6.783967e+00  \n",
      "max    1.738083e+08  \n"
     ]
    }
   ],
   "source": [
    "print(test.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f545deb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parameter1</th>\n",
       "      <th>Parameter2</th>\n",
       "      <th>Parameter3</th>\n",
       "      <th>Parameter4</th>\n",
       "      <th>Parameter5</th>\n",
       "      <th>Parameter6</th>\n",
       "      <th>Parameter7</th>\n",
       "      <th>Parameter8</th>\n",
       "      <th>Parameter9</th>\n",
       "      <th>Parameter10</th>\n",
       "      <th>Attribute1</th>\n",
       "      <th>Attribute2</th>\n",
       "      <th>Attribute3</th>\n",
       "      <th>Attribute4</th>\n",
       "      <th>Attribute5</th>\n",
       "      <th>Attribute6</th>\n",
       "      <th>Attribute7</th>\n",
       "      <th>Attribute8</th>\n",
       "      <th>Attribute9</th>\n",
       "      <th>Attribute10</th>\n",
       "      <th>Quality_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001660</td>\n",
       "      <td>0.591013</td>\n",
       "      <td>147.608373</td>\n",
       "      <td>38.186345</td>\n",
       "      <td>0.000421</td>\n",
       "      <td>0.000612</td>\n",
       "      <td>2286.523413</td>\n",
       "      <td>0.035407</td>\n",
       "      <td>0.593081</td>\n",
       "      <td>1.010385</td>\n",
       "      <td>6.856075</td>\n",
       "      <td>0.168761</td>\n",
       "      <td>1.098755</td>\n",
       "      <td>36.955992</td>\n",
       "      <td>8.454598</td>\n",
       "      <td>11.438066</td>\n",
       "      <td>177.243120</td>\n",
       "      <td>338.729256</td>\n",
       "      <td>2.021704</td>\n",
       "      <td>0.079526</td>\n",
       "      <td>Pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.601749</td>\n",
       "      <td>0.015052</td>\n",
       "      <td>0.035864</td>\n",
       "      <td>51.130326</td>\n",
       "      <td>0.000909</td>\n",
       "      <td>0.002397</td>\n",
       "      <td>2286.523413</td>\n",
       "      <td>0.035407</td>\n",
       "      <td>0.593081</td>\n",
       "      <td>1.010385</td>\n",
       "      <td>0.000362</td>\n",
       "      <td>11.649033</td>\n",
       "      <td>0.066671</td>\n",
       "      <td>225.632949</td>\n",
       "      <td>0.481860</td>\n",
       "      <td>20597.447822</td>\n",
       "      <td>3.723330</td>\n",
       "      <td>15.376190</td>\n",
       "      <td>0.986973</td>\n",
       "      <td>4.634376</td>\n",
       "      <td>Fail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.098039</td>\n",
       "      <td>69.233685</td>\n",
       "      <td>0.080920</td>\n",
       "      <td>0.112265</td>\n",
       "      <td>0.000909</td>\n",
       "      <td>0.001972</td>\n",
       "      <td>2286.523413</td>\n",
       "      <td>0.035407</td>\n",
       "      <td>0.593081</td>\n",
       "      <td>1.010385</td>\n",
       "      <td>0.022201</td>\n",
       "      <td>0.078213</td>\n",
       "      <td>110.079689</td>\n",
       "      <td>2.208138</td>\n",
       "      <td>0.073525</td>\n",
       "      <td>236.079314</td>\n",
       "      <td>0.064196</td>\n",
       "      <td>0.576302</td>\n",
       "      <td>33.875790</td>\n",
       "      <td>1.813727</td>\n",
       "      <td>Fail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18.181860</td>\n",
       "      <td>0.047325</td>\n",
       "      <td>0.018061</td>\n",
       "      <td>1.098102</td>\n",
       "      <td>0.000909</td>\n",
       "      <td>0.002397</td>\n",
       "      <td>2286.523413</td>\n",
       "      <td>0.035407</td>\n",
       "      <td>0.593081</td>\n",
       "      <td>1.010385</td>\n",
       "      <td>1.459004</td>\n",
       "      <td>0.380281</td>\n",
       "      <td>0.011491</td>\n",
       "      <td>0.654517</td>\n",
       "      <td>0.025872</td>\n",
       "      <td>176.948915</td>\n",
       "      <td>0.029777</td>\n",
       "      <td>0.246726</td>\n",
       "      <td>27.117165</td>\n",
       "      <td>0.081819</td>\n",
       "      <td>Fail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.012085</td>\n",
       "      <td>0.008749</td>\n",
       "      <td>0.005509</td>\n",
       "      <td>524.327396</td>\n",
       "      <td>0.000909</td>\n",
       "      <td>0.002397</td>\n",
       "      <td>2286.523413</td>\n",
       "      <td>0.035407</td>\n",
       "      <td>0.593081</td>\n",
       "      <td>1.010385</td>\n",
       "      <td>11.576647</td>\n",
       "      <td>1.555672</td>\n",
       "      <td>38.613386</td>\n",
       "      <td>0.260989</td>\n",
       "      <td>0.009380</td>\n",
       "      <td>194.798039</td>\n",
       "      <td>0.055053</td>\n",
       "      <td>0.014725</td>\n",
       "      <td>13.569707</td>\n",
       "      <td>18.138496</td>\n",
       "      <td>Fail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.004062</td>\n",
       "      <td>14.556483</td>\n",
       "      <td>0.786945</td>\n",
       "      <td>0.010545</td>\n",
       "      <td>0.000525</td>\n",
       "      <td>0.001623</td>\n",
       "      <td>2286.523413</td>\n",
       "      <td>0.035407</td>\n",
       "      <td>0.593081</td>\n",
       "      <td>1.010385</td>\n",
       "      <td>0.001555</td>\n",
       "      <td>8.998940</td>\n",
       "      <td>6.392712</td>\n",
       "      <td>16.107479</td>\n",
       "      <td>1.016071</td>\n",
       "      <td>86.064258</td>\n",
       "      <td>0.576380</td>\n",
       "      <td>123.057489</td>\n",
       "      <td>16.133884</td>\n",
       "      <td>0.598517</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.438449</td>\n",
       "      <td>1.232559</td>\n",
       "      <td>2.882699</td>\n",
       "      <td>0.610757</td>\n",
       "      <td>1.600654</td>\n",
       "      <td>0.464037</td>\n",
       "      <td>0.600827</td>\n",
       "      <td>17.850021</td>\n",
       "      <td>0.051850</td>\n",
       "      <td>0.010192</td>\n",
       "      <td>10.690637</td>\n",
       "      <td>0.034557</td>\n",
       "      <td>0.000971</td>\n",
       "      <td>1.021246</td>\n",
       "      <td>1.791292</td>\n",
       "      <td>0.377312</td>\n",
       "      <td>0.035493</td>\n",
       "      <td>0.146690</td>\n",
       "      <td>41.285376</td>\n",
       "      <td>5.985572</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>48159.917401</td>\n",
       "      <td>0.002987</td>\n",
       "      <td>14.863813</td>\n",
       "      <td>0.063287</td>\n",
       "      <td>1.434060</td>\n",
       "      <td>0.314162</td>\n",
       "      <td>0.600827</td>\n",
       "      <td>17.850021</td>\n",
       "      <td>0.051850</td>\n",
       "      <td>0.010192</td>\n",
       "      <td>0.057851</td>\n",
       "      <td>0.255094</td>\n",
       "      <td>0.090395</td>\n",
       "      <td>21.035514</td>\n",
       "      <td>29.608630</td>\n",
       "      <td>0.581454</td>\n",
       "      <td>0.615609</td>\n",
       "      <td>3.321156</td>\n",
       "      <td>0.013034</td>\n",
       "      <td>0.045039</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.456601</td>\n",
       "      <td>52.381578</td>\n",
       "      <td>20.625283</td>\n",
       "      <td>366.074831</td>\n",
       "      <td>1.434060</td>\n",
       "      <td>0.258497</td>\n",
       "      <td>0.600827</td>\n",
       "      <td>17.850021</td>\n",
       "      <td>0.051850</td>\n",
       "      <td>0.010192</td>\n",
       "      <td>120.791843</td>\n",
       "      <td>49.151635</td>\n",
       "      <td>43.315938</td>\n",
       "      <td>0.581297</td>\n",
       "      <td>0.753916</td>\n",
       "      <td>0.610076</td>\n",
       "      <td>0.029777</td>\n",
       "      <td>0.007033</td>\n",
       "      <td>3.397996</td>\n",
       "      <td>20.322889</td>\n",
       "      <td>Pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000109</td>\n",
       "      <td>4.784654</td>\n",
       "      <td>31.916672</td>\n",
       "      <td>20.672388</td>\n",
       "      <td>1.284806</td>\n",
       "      <td>0.175007</td>\n",
       "      <td>0.600827</td>\n",
       "      <td>17.850021</td>\n",
       "      <td>0.051850</td>\n",
       "      <td>0.010192</td>\n",
       "      <td>0.000306</td>\n",
       "      <td>0.020348</td>\n",
       "      <td>58.681014</td>\n",
       "      <td>8.387914</td>\n",
       "      <td>33.362518</td>\n",
       "      <td>0.108174</td>\n",
       "      <td>1.356619</td>\n",
       "      <td>1.081445</td>\n",
       "      <td>0.056060</td>\n",
       "      <td>0.413597</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Parameter1  Parameter2  Parameter3  Parameter4  Parameter5  Parameter6  \\\n",
       "0      0.001660    0.591013  147.608373   38.186345    0.000421    0.000612   \n",
       "1      1.601749    0.015052    0.035864   51.130326    0.000909    0.002397   \n",
       "2      0.098039   69.233685    0.080920    0.112265    0.000909    0.001972   \n",
       "3     18.181860    0.047325    0.018061    1.098102    0.000909    0.002397   \n",
       "4      0.012085    0.008749    0.005509  524.327396    0.000909    0.002397   \n",
       "5      0.004062   14.556483    0.786945    0.010545    0.000525    0.001623   \n",
       "6      0.438449    1.232559    2.882699    0.610757    1.600654    0.464037   \n",
       "7  48159.917401    0.002987   14.863813    0.063287    1.434060    0.314162   \n",
       "8      1.456601   52.381578   20.625283  366.074831    1.434060    0.258497   \n",
       "9      0.000109    4.784654   31.916672   20.672388    1.284806    0.175007   \n",
       "\n",
       "    Parameter7  Parameter8  Parameter9  Parameter10  Attribute1  Attribute2  \\\n",
       "0  2286.523413    0.035407    0.593081     1.010385    6.856075    0.168761   \n",
       "1  2286.523413    0.035407    0.593081     1.010385    0.000362   11.649033   \n",
       "2  2286.523413    0.035407    0.593081     1.010385    0.022201    0.078213   \n",
       "3  2286.523413    0.035407    0.593081     1.010385    1.459004    0.380281   \n",
       "4  2286.523413    0.035407    0.593081     1.010385   11.576647    1.555672   \n",
       "5  2286.523413    0.035407    0.593081     1.010385    0.001555    8.998940   \n",
       "6     0.600827   17.850021    0.051850     0.010192   10.690637    0.034557   \n",
       "7     0.600827   17.850021    0.051850     0.010192    0.057851    0.255094   \n",
       "8     0.600827   17.850021    0.051850     0.010192  120.791843   49.151635   \n",
       "9     0.600827   17.850021    0.051850     0.010192    0.000306    0.020348   \n",
       "\n",
       "   Attribute3  Attribute4  Attribute5    Attribute6  Attribute7  Attribute8  \\\n",
       "0    1.098755   36.955992    8.454598     11.438066  177.243120  338.729256   \n",
       "1    0.066671  225.632949    0.481860  20597.447822    3.723330   15.376190   \n",
       "2  110.079689    2.208138    0.073525    236.079314    0.064196    0.576302   \n",
       "3    0.011491    0.654517    0.025872    176.948915    0.029777    0.246726   \n",
       "4   38.613386    0.260989    0.009380    194.798039    0.055053    0.014725   \n",
       "5    6.392712   16.107479    1.016071     86.064258    0.576380  123.057489   \n",
       "6    0.000971    1.021246    1.791292      0.377312    0.035493    0.146690   \n",
       "7    0.090395   21.035514   29.608630      0.581454    0.615609    3.321156   \n",
       "8   43.315938    0.581297    0.753916      0.610076    0.029777    0.007033   \n",
       "9   58.681014    8.387914   33.362518      0.108174    1.356619    1.081445   \n",
       "\n",
       "   Attribute9  Attribute10 Quality_label  \n",
       "0    2.021704     0.079526          Pass  \n",
       "1    0.986973     4.634376          Fail  \n",
       "2   33.875790     1.813727          Fail  \n",
       "3   27.117165     0.081819          Fail  \n",
       "4   13.569707    18.138496          Fail  \n",
       "5   16.133884     0.598517          Good  \n",
       "6   41.285376     5.985572          Good  \n",
       "7    0.013034     0.045039          Good  \n",
       "8    3.397996    20.322889          Pass  \n",
       "9    0.056060     0.413597          Good  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94332c1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parameter1</th>\n",
       "      <th>Parameter2</th>\n",
       "      <th>Parameter3</th>\n",
       "      <th>Parameter4</th>\n",
       "      <th>Parameter5</th>\n",
       "      <th>Parameter6</th>\n",
       "      <th>Parameter7</th>\n",
       "      <th>Parameter8</th>\n",
       "      <th>Parameter9</th>\n",
       "      <th>Parameter10</th>\n",
       "      <th>Attribute1</th>\n",
       "      <th>Attribute2</th>\n",
       "      <th>Attribute3</th>\n",
       "      <th>Attribute4</th>\n",
       "      <th>Attribute5</th>\n",
       "      <th>Attribute6</th>\n",
       "      <th>Attribute7</th>\n",
       "      <th>Attribute8</th>\n",
       "      <th>Attribute9</th>\n",
       "      <th>Attribute10</th>\n",
       "      <th>Quality_label</th>\n",
       "      <th>Group</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001660</td>\n",
       "      <td>0.591013</td>\n",
       "      <td>147.608373</td>\n",
       "      <td>38.186345</td>\n",
       "      <td>0.000421</td>\n",
       "      <td>0.000612</td>\n",
       "      <td>2286.523413</td>\n",
       "      <td>0.035407</td>\n",
       "      <td>0.593081</td>\n",
       "      <td>1.010385</td>\n",
       "      <td>6.856075</td>\n",
       "      <td>0.168761</td>\n",
       "      <td>1.098755</td>\n",
       "      <td>36.955992</td>\n",
       "      <td>8.454598</td>\n",
       "      <td>11.438066</td>\n",
       "      <td>177.243120</td>\n",
       "      <td>338.729256</td>\n",
       "      <td>2.021704</td>\n",
       "      <td>0.079526</td>\n",
       "      <td>Pass</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.601749</td>\n",
       "      <td>0.015052</td>\n",
       "      <td>0.035864</td>\n",
       "      <td>51.130326</td>\n",
       "      <td>0.000909</td>\n",
       "      <td>0.002397</td>\n",
       "      <td>2286.523413</td>\n",
       "      <td>0.035407</td>\n",
       "      <td>0.593081</td>\n",
       "      <td>1.010385</td>\n",
       "      <td>0.000362</td>\n",
       "      <td>11.649033</td>\n",
       "      <td>0.066671</td>\n",
       "      <td>225.632949</td>\n",
       "      <td>0.481860</td>\n",
       "      <td>20597.447822</td>\n",
       "      <td>3.723330</td>\n",
       "      <td>15.376190</td>\n",
       "      <td>0.986973</td>\n",
       "      <td>4.634376</td>\n",
       "      <td>Fail</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.098039</td>\n",
       "      <td>69.233685</td>\n",
       "      <td>0.080920</td>\n",
       "      <td>0.112265</td>\n",
       "      <td>0.000909</td>\n",
       "      <td>0.001972</td>\n",
       "      <td>2286.523413</td>\n",
       "      <td>0.035407</td>\n",
       "      <td>0.593081</td>\n",
       "      <td>1.010385</td>\n",
       "      <td>0.022201</td>\n",
       "      <td>0.078213</td>\n",
       "      <td>110.079689</td>\n",
       "      <td>2.208138</td>\n",
       "      <td>0.073525</td>\n",
       "      <td>236.079314</td>\n",
       "      <td>0.064196</td>\n",
       "      <td>0.576302</td>\n",
       "      <td>33.875790</td>\n",
       "      <td>1.813727</td>\n",
       "      <td>Fail</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18.181860</td>\n",
       "      <td>0.047325</td>\n",
       "      <td>0.018061</td>\n",
       "      <td>1.098102</td>\n",
       "      <td>0.000909</td>\n",
       "      <td>0.002397</td>\n",
       "      <td>2286.523413</td>\n",
       "      <td>0.035407</td>\n",
       "      <td>0.593081</td>\n",
       "      <td>1.010385</td>\n",
       "      <td>1.459004</td>\n",
       "      <td>0.380281</td>\n",
       "      <td>0.011491</td>\n",
       "      <td>0.654517</td>\n",
       "      <td>0.025872</td>\n",
       "      <td>176.948915</td>\n",
       "      <td>0.029777</td>\n",
       "      <td>0.246726</td>\n",
       "      <td>27.117165</td>\n",
       "      <td>0.081819</td>\n",
       "      <td>Fail</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.012085</td>\n",
       "      <td>0.008749</td>\n",
       "      <td>0.005509</td>\n",
       "      <td>524.327396</td>\n",
       "      <td>0.000909</td>\n",
       "      <td>0.002397</td>\n",
       "      <td>2286.523413</td>\n",
       "      <td>0.035407</td>\n",
       "      <td>0.593081</td>\n",
       "      <td>1.010385</td>\n",
       "      <td>11.576647</td>\n",
       "      <td>1.555672</td>\n",
       "      <td>38.613386</td>\n",
       "      <td>0.260989</td>\n",
       "      <td>0.009380</td>\n",
       "      <td>194.798039</td>\n",
       "      <td>0.055053</td>\n",
       "      <td>0.014725</td>\n",
       "      <td>13.569707</td>\n",
       "      <td>18.138496</td>\n",
       "      <td>Fail</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.004062</td>\n",
       "      <td>14.556483</td>\n",
       "      <td>0.786945</td>\n",
       "      <td>0.010545</td>\n",
       "      <td>0.000525</td>\n",
       "      <td>0.001623</td>\n",
       "      <td>2286.523413</td>\n",
       "      <td>0.035407</td>\n",
       "      <td>0.593081</td>\n",
       "      <td>1.010385</td>\n",
       "      <td>0.001555</td>\n",
       "      <td>8.998940</td>\n",
       "      <td>6.392712</td>\n",
       "      <td>16.107479</td>\n",
       "      <td>1.016071</td>\n",
       "      <td>86.064258</td>\n",
       "      <td>0.576380</td>\n",
       "      <td>123.057489</td>\n",
       "      <td>16.133884</td>\n",
       "      <td>0.598517</td>\n",
       "      <td>Good</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.438449</td>\n",
       "      <td>1.232559</td>\n",
       "      <td>2.882699</td>\n",
       "      <td>0.610757</td>\n",
       "      <td>1.600654</td>\n",
       "      <td>0.464037</td>\n",
       "      <td>0.600827</td>\n",
       "      <td>17.850021</td>\n",
       "      <td>0.051850</td>\n",
       "      <td>0.010192</td>\n",
       "      <td>10.690637</td>\n",
       "      <td>0.034557</td>\n",
       "      <td>0.000971</td>\n",
       "      <td>1.021246</td>\n",
       "      <td>1.791292</td>\n",
       "      <td>0.377312</td>\n",
       "      <td>0.035493</td>\n",
       "      <td>0.146690</td>\n",
       "      <td>41.285376</td>\n",
       "      <td>5.985572</td>\n",
       "      <td>Good</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>48159.917401</td>\n",
       "      <td>0.002987</td>\n",
       "      <td>14.863813</td>\n",
       "      <td>0.063287</td>\n",
       "      <td>1.434060</td>\n",
       "      <td>0.314162</td>\n",
       "      <td>0.600827</td>\n",
       "      <td>17.850021</td>\n",
       "      <td>0.051850</td>\n",
       "      <td>0.010192</td>\n",
       "      <td>0.057851</td>\n",
       "      <td>0.255094</td>\n",
       "      <td>0.090395</td>\n",
       "      <td>21.035514</td>\n",
       "      <td>29.608630</td>\n",
       "      <td>0.581454</td>\n",
       "      <td>0.615609</td>\n",
       "      <td>3.321156</td>\n",
       "      <td>0.013034</td>\n",
       "      <td>0.045039</td>\n",
       "      <td>Good</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.456601</td>\n",
       "      <td>52.381578</td>\n",
       "      <td>20.625283</td>\n",
       "      <td>366.074831</td>\n",
       "      <td>1.434060</td>\n",
       "      <td>0.258497</td>\n",
       "      <td>0.600827</td>\n",
       "      <td>17.850021</td>\n",
       "      <td>0.051850</td>\n",
       "      <td>0.010192</td>\n",
       "      <td>120.791843</td>\n",
       "      <td>49.151635</td>\n",
       "      <td>43.315938</td>\n",
       "      <td>0.581297</td>\n",
       "      <td>0.753916</td>\n",
       "      <td>0.610076</td>\n",
       "      <td>0.029777</td>\n",
       "      <td>0.007033</td>\n",
       "      <td>3.397996</td>\n",
       "      <td>20.322889</td>\n",
       "      <td>Pass</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000109</td>\n",
       "      <td>4.784654</td>\n",
       "      <td>31.916672</td>\n",
       "      <td>20.672388</td>\n",
       "      <td>1.284806</td>\n",
       "      <td>0.175007</td>\n",
       "      <td>0.600827</td>\n",
       "      <td>17.850021</td>\n",
       "      <td>0.051850</td>\n",
       "      <td>0.010192</td>\n",
       "      <td>0.000306</td>\n",
       "      <td>0.020348</td>\n",
       "      <td>58.681014</td>\n",
       "      <td>8.387914</td>\n",
       "      <td>33.362518</td>\n",
       "      <td>0.108174</td>\n",
       "      <td>1.356619</td>\n",
       "      <td>1.081445</td>\n",
       "      <td>0.056060</td>\n",
       "      <td>0.413597</td>\n",
       "      <td>Good</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Parameter1  Parameter2  Parameter3  Parameter4  Parameter5  Parameter6  \\\n",
       "0      0.001660    0.591013  147.608373   38.186345    0.000421    0.000612   \n",
       "1      1.601749    0.015052    0.035864   51.130326    0.000909    0.002397   \n",
       "2      0.098039   69.233685    0.080920    0.112265    0.000909    0.001972   \n",
       "3     18.181860    0.047325    0.018061    1.098102    0.000909    0.002397   \n",
       "4      0.012085    0.008749    0.005509  524.327396    0.000909    0.002397   \n",
       "5      0.004062   14.556483    0.786945    0.010545    0.000525    0.001623   \n",
       "6      0.438449    1.232559    2.882699    0.610757    1.600654    0.464037   \n",
       "7  48159.917401    0.002987   14.863813    0.063287    1.434060    0.314162   \n",
       "8      1.456601   52.381578   20.625283  366.074831    1.434060    0.258497   \n",
       "9      0.000109    4.784654   31.916672   20.672388    1.284806    0.175007   \n",
       "\n",
       "    Parameter7  Parameter8  Parameter9  Parameter10  Attribute1  Attribute2  \\\n",
       "0  2286.523413    0.035407    0.593081     1.010385    6.856075    0.168761   \n",
       "1  2286.523413    0.035407    0.593081     1.010385    0.000362   11.649033   \n",
       "2  2286.523413    0.035407    0.593081     1.010385    0.022201    0.078213   \n",
       "3  2286.523413    0.035407    0.593081     1.010385    1.459004    0.380281   \n",
       "4  2286.523413    0.035407    0.593081     1.010385   11.576647    1.555672   \n",
       "5  2286.523413    0.035407    0.593081     1.010385    0.001555    8.998940   \n",
       "6     0.600827   17.850021    0.051850     0.010192   10.690637    0.034557   \n",
       "7     0.600827   17.850021    0.051850     0.010192    0.057851    0.255094   \n",
       "8     0.600827   17.850021    0.051850     0.010192  120.791843   49.151635   \n",
       "9     0.600827   17.850021    0.051850     0.010192    0.000306    0.020348   \n",
       "\n",
       "   Attribute3  Attribute4  Attribute5    Attribute6  Attribute7  Attribute8  \\\n",
       "0    1.098755   36.955992    8.454598     11.438066  177.243120  338.729256   \n",
       "1    0.066671  225.632949    0.481860  20597.447822    3.723330   15.376190   \n",
       "2  110.079689    2.208138    0.073525    236.079314    0.064196    0.576302   \n",
       "3    0.011491    0.654517    0.025872    176.948915    0.029777    0.246726   \n",
       "4   38.613386    0.260989    0.009380    194.798039    0.055053    0.014725   \n",
       "5    6.392712   16.107479    1.016071     86.064258    0.576380  123.057489   \n",
       "6    0.000971    1.021246    1.791292      0.377312    0.035493    0.146690   \n",
       "7    0.090395   21.035514   29.608630      0.581454    0.615609    3.321156   \n",
       "8   43.315938    0.581297    0.753916      0.610076    0.029777    0.007033   \n",
       "9   58.681014    8.387914   33.362518      0.108174    1.356619    1.081445   \n",
       "\n",
       "   Attribute9  Attribute10 Quality_label  Group  label  \n",
       "0    2.021704     0.079526          Pass    NaN    2.0  \n",
       "1    0.986973     4.634376          Fail    NaN    3.0  \n",
       "2   33.875790     1.813727          Fail    NaN    3.0  \n",
       "3   27.117165     0.081819          Fail    NaN    3.0  \n",
       "4   13.569707    18.138496          Fail    NaN    3.0  \n",
       "5   16.133884     0.598517          Good    NaN    1.0  \n",
       "6   41.285376     5.985572          Good    NaN    1.0  \n",
       "7    0.013034     0.045039          Good    NaN    1.0  \n",
       "8    3.397996    20.322889          Pass    NaN    2.0  \n",
       "9    0.056060     0.413597          Good    NaN    1.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = train.append(test).reset_index(drop=True)\n",
    "dit = {'Excellent': 0, 'Good': 1, 'Pass': 2, 'Fail': 3}\n",
    "data['label'] = data['Quality_label'].map(dit)\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f399ba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter1       0\n",
      "Parameter2       0\n",
      "Parameter3       0\n",
      "Parameter4       0\n",
      "Parameter5       0\n",
      "Parameter6       0\n",
      "Parameter7       0\n",
      "Parameter8       0\n",
      "Parameter9       0\n",
      "Parameter10      0\n",
      "Attribute1       0\n",
      "Attribute2       0\n",
      "Attribute3       0\n",
      "Attribute4       0\n",
      "Attribute5       0\n",
      "Attribute6       0\n",
      "Attribute7       0\n",
      "Attribute8       0\n",
      "Attribute9       0\n",
      "Attribute10      0\n",
      "Quality_label    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ccb27c5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "col_name = train.columns\n",
    "Notdlts_count = []\n",
    "for i in col_name:\n",
    "    Notdlts = len(train[i].drop_duplicates())/6000\n",
    "    Notdlts_count.append(Notdlts)\n",
    "\n",
    "plt.figure(figsize=(20,5))\n",
    "\n",
    "\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']\n",
    "# plt.rcParams['font.sans-serif'] = ['KaiTi']   # 指定默认字体\n",
    "plt.rcParams['axes.unicode_minus'] = False   # 解决保存图像是负号'-'显示为方块的问题\n",
    "\n",
    "plt.plot(col_name, Notdlts_count, c='r')\n",
    "plt.title('计算非重复值的占比')                 \n",
    "plt.xlabel('字段名')                        \n",
    "plt.ylabel('非重复数据在全数据上的占比')  \n",
    "plt.xticks(rotation=90)                   \n",
    "for x,y in zip(col_name,Notdlts_count):\n",
    "    plt.text(x,y,'%.3f' % y,fontdict={'fontsize':15}) \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bae47789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class0 is len is 1107\n",
      "class1 is len is 1584\n",
      "class2 is len is 2417\n",
      "class3 is len is 892\n"
     ]
    }
   ],
   "source": [
    "feature_name = ['Parameter{0}'.format(i) for i in range(start_index, end_index)]\n",
    "tr_index = ~data['label'].isnull()\n",
    "X_train_org = data[tr_index][feature_name].reset_index(drop=True)\n",
    "y = data[tr_index]['label'].reset_index(drop=True).astype(int)\n",
    "X_test_org = data[~tr_index][feature_name].reset_index(drop=True)\n",
    "\n",
    "X_train_dis = pd.DataFrame()\n",
    "X_test_dis = pd.DataFrame()\n",
    "\n",
    "classdf = pd.DataFrame(y)\n",
    "for classindex in range(4):\n",
    "    class_row_index_list = classdf[(classdf['label'] == classindex)].index.tolist()\n",
    "\n",
    "    df_train_temp = X_train_org.iloc[class_row_index_list]\n",
    "\n",
    "    print('class{0} is len is {1}'.format(classindex, len(df_train_temp)))\n",
    "\n",
    "    for Parameter in range(start_index, end_index):\n",
    "        Parameter_std = df_train_temp['Parameter{0}'.format(Parameter)].std()\n",
    "        Parameter_mean = df_train_temp['Parameter{0}'.format(Parameter)].mean()\n",
    "        X_train_dis['Parameter{0}class{1}dis_mean'.format(Parameter, classindex)] = X_train_org['Parameter{0}'.format(\n",
    "            Parameter)] - Parameter_mean\n",
    "        X_test_dis['Parameter{0}class{1}dis_mean'.format(Parameter, classindex)] = X_test_org['Parameter{0}'.format(\n",
    "            Parameter)] - Parameter_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee99c353",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.feature_selection import SelectPercentile\n",
    "\n",
    "\n",
    "def make_feature(df_temp, degree_level):\n",
    "    poly = PolynomialFeatures(degree=degree_level, include_bias=False, interaction_only=False)\n",
    "    X_ploly = poly.fit_transform(df_temp)\n",
    "    df_temp = pd.DataFrame(X_ploly, columns=poly.get_feature_names())\n",
    "    return df_temp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "722cf906",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_org_ploly3 = pd.DataFrame()\n",
    "X_test_org_ploly3 = pd.DataFrame()\n",
    "for Parameter in range(start_index, end_index):\n",
    "    Parameter_std = X_train_org['Parameter{0}'.format(Parameter)].std()\n",
    "    Parameter_mean = X_train_org['Parameter{0}'.format(Parameter)].mean()\n",
    "    X_train_org_ploly3['Parameter{0}'.format(Parameter)] = (X_train_org['Parameter{0}'.format(\n",
    "        Parameter)] - Parameter_mean) / Parameter_std\n",
    "    X_test_org_ploly3['Parameter{0}'.format(Parameter)] = (X_test_org['Parameter{0}'.format(\n",
    "        Parameter)] - Parameter_mean) / Parameter_std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "991409bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ploly_3 = make_feature(X_train_org_ploly3, 3)\n",
    "select = SelectPercentile(percentile=100) \n",
    "select.fit(X_train_ploly_3, y)\n",
    "mask = select.get_support()\n",
    "\n",
    "feature_used = []\n",
    "for index in range(len(mask)):\n",
    "    if mask[index]:\n",
    "        feature_used.append(list(X_train_ploly_3.columns.values)[index])\n",
    "\n",
    "X_train_ploly_3 = X_train_ploly_3[feature_used]\n",
    "X_test_ploly_3 = make_feature(X_test_org_ploly3, 3)\n",
    "X_test_ploly_3 = X_test_ploly_3[feature_used]\n",
    "\n",
    "clusterdic = {1: 5, 2: 4, 3: 4, 4: 6, 5: 6, 6: 6, 7: 3, 8: 4, 9: 2, 10: 5}\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "\n",
    "def getclusterfeature(df_train, df_predict1, df_predict2):\n",
    "    df_temp1 = pd.DataFrame()\n",
    "    df_temp2 = pd.DataFrame()\n",
    "    for i in range(start_index, end_index):\n",
    "        colindex = i\n",
    "        df_features = df_train[['Parameter{0}'.format(colindex)]]\n",
    "\n",
    "        estimator = KMeans(n_clusters=clusterdic[colindex])  # 构造聚类器\n",
    "        estimator.fit(df_features)\n",
    "        predictclass1 = estimator.predict(df_predict1[['Parameter{0}'.format(colindex)]])\n",
    "        df_temp1['Parametercluter{0}'.format(colindex)] = predictclass1.tolist()\n",
    "        predictclass2 = estimator.predict(df_predict2[['Parameter{0}'.format(colindex)]])\n",
    "        df_temp2['Parametercluter{0}'.format(colindex)] = predictclass2.tolist()\n",
    "\n",
    "    return df_temp1, df_temp2\n",
    "\n",
    "X_train_cluster, X_test_cluster = getclusterfeature(X_train_org, X_train_org, X_test_org)\n",
    "\n",
    "from sklearn.feature_selection import SelectPercentile\n",
    "\n",
    "percent = 13\n",
    "X_train = pd.concat([X_train_dis, X_train_ploly_3, X_train_cluster], axis=1)\n",
    "X_test = pd.concat([X_test_dis, X_test_ploly_3, X_test_cluster], axis=1)\n",
    "list_file = open('percent.txt', 'a')\n",
    "\n",
    "\n",
    "select = SelectPercentile(percentile=percent)  \n",
    "select.fit(X_train, y)\n",
    "\n",
    "mask = select.get_support()\n",
    "\n",
    "feature_used = []\n",
    "for index in range(len(mask)):\n",
    "    if mask[index]:\n",
    "        feature_used.append(list(X_train.columns.values)[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "858410f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最终特征选择\n",
      "['Parameter5class0dis_mean', 'Parameter6class0dis_mean', 'Parameter7class0dis_mean', 'Parameter10class0dis_mean', 'Parameter5class1dis_mean', 'Parameter6class1dis_mean', 'Parameter7class1dis_mean', 'Parameter10class1dis_mean', 'Parameter5class2dis_mean', 'Parameter6class2dis_mean', 'Parameter7class2dis_mean', 'Parameter10class2dis_mean', 'Parameter5class3dis_mean', 'Parameter6class3dis_mean', 'Parameter7class3dis_mean', 'Parameter10class3dis_mean', 'x4', 'x5', 'x6', 'x9', 'x4^2', 'x4 x5', 'x4 x6', 'x5^2', 'x5 x6', 'x6^2', 'x9^2', 'x2 x6^2', 'x4^3', 'x4^2 x5', 'x4^2 x6', 'x4 x5^2', 'x4 x5 x6', 'x4 x6^2', 'x5^3', 'x5^2 x6', 'x5 x6^2', 'x6^3', 'x6^2 x7', 'x7 x9^2', 'x9^3', 'Parametercluter5', 'Parametercluter6', 'Parametercluter7']\n",
      "最终特征维度\n",
      "(6000, 44) (6000, 44)\n"
     ]
    }
   ],
   "source": [
    "print('最终特征选择')\n",
    "print(feature_used)\n",
    "list_file.write(','.join(feature_used) + '\\n')\n",
    "X_train = X_train[feature_used]\n",
    "X_test = X_test[feature_used]\n",
    "print('最终特征维度')\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5da78d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = np.zeros((X_test.shape[0],4)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "03ae446b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_loss 1.5451948419850454\n",
      "gbdt_ac 0.3045\n",
      "MAE 0.05329754283727099\n",
      "gdbt_score 0.6523261765920957\n",
      "--------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gdbt_model():\n",
    "    model =GradientBoostingClassifier()\n",
    "    model.fit(X_train,y)\n",
    "    pred = model.predict_proba(X_test) \n",
    "    MAE = 1/(1 + np.sum(np.absolute(np.eye(4)[y] - pred))/480)\n",
    "    gdbt_score = 1/(1+10*MAE)\n",
    "    print('log_loss',log_loss(pd.get_dummies(y).values, pred))\n",
    "    print('gbdt_ac',accuracy_score(y,np.argmax(pred,axis = 1)))\n",
    "    print('MAE',1/(1 + np.sum(np.absolute(np.eye(4)[y] - pred))/480))\n",
    "    print('gdbt_score',1/(1+10*MAE))\n",
    "    print('--------------------------------')\n",
    "\n",
    "    return model\n",
    "gdbt_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "46efee78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 1.3650361\ttotal: 197ms\tremaining: 3m 56s\n",
      "300:\tlearn: 1.0011697\ttotal: 3.74s\tremaining: 11.2s\n",
      "600:\tlearn: 0.9235854\ttotal: 7.32s\tremaining: 7.3s\n",
      "900:\tlearn: 0.8634229\ttotal: 11.2s\tremaining: 3.7s\n",
      "1199:\tlearn: 0.8161327\ttotal: 14.9s\tremaining: 0us\n",
      "log_loss 1.657185490182091\n",
      "cbt_ac 0.3016666666666667\n",
      "MAE 0.05326152536899948\n",
      "cbt_score 0.6524794775416427\n",
      "--------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x2be89a27d30>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cbt_model():\n",
    "    model = cbt.CatBoostClassifier(iterations=1200, learning_rate=0.05, verbose=300,\n",
    "                                       early_stopping_rounds=400, \n",
    "                                        loss_function='MultiClass')\n",
    "    model.fit(X_train,y)\n",
    "    \n",
    "    pred = model.predict_proba(X_test) \n",
    "    MAE = 1/(1 + np.sum(np.absolute(np.eye(4)[y] - pred))/480)\n",
    "    gdbt_then_score = 1/(1+10*MAE)\n",
    "    print('log_loss',log_loss(pd.get_dummies(y).values, pred))\n",
    "    print('cbt_ac',accuracy_score(y,np.argmax(pred,axis = 1)))\n",
    "    print('MAE',1/(1 + np.sum(np.absolute(np.eye(4)[y] - pred))/480))\n",
    "    print('cbt_score',1/(1+10*MAE))\n",
    "    print('--------------------------------')\n",
    "\n",
    "    return model\n",
    "cbt_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8cd912c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.010271\n",
      "[LightGBM] [Debug] init for col-wise cost 0.000057 seconds, init for row-wise cost 0.004381 seconds\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006283 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4580\n",
      "[LightGBM] [Info] Number of data points in the train set: 6000, number of used features: 44\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score -1.690106\n",
      "[LightGBM] [Info] Start training from score -1.331806\n",
      "[LightGBM] [Info] Start training from score -0.909232\n",
      "[LightGBM] [Info] Start training from score -1.906049\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[1]\tvalid_0's multi_logloss: 1.31594\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[2]\tvalid_0's multi_logloss: 1.3233\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[3]\tvalid_0's multi_logloss: 1.33299\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[4]\tvalid_0's multi_logloss: 1.34515\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[5]\tvalid_0's multi_logloss: 1.35721\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[6]\tvalid_0's multi_logloss: 1.37093\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[7]\tvalid_0's multi_logloss: 1.38359\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[8]\tvalid_0's multi_logloss: 1.39705\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[9]\tvalid_0's multi_logloss: 1.40986\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[10]\tvalid_0's multi_logloss: 1.42294\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[11]\tvalid_0's multi_logloss: 1.43466\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[12]\tvalid_0's multi_logloss: 1.44635\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[13]\tvalid_0's multi_logloss: 1.45763\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[14]\tvalid_0's multi_logloss: 1.46767\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[15]\tvalid_0's multi_logloss: 1.4788\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[16]\tvalid_0's multi_logloss: 1.48838\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 18\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[17]\tvalid_0's multi_logloss: 1.49756\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[18]\tvalid_0's multi_logloss: 1.50654\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[19]\tvalid_0's multi_logloss: 1.5149\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[20]\tvalid_0's multi_logloss: 1.52308\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 20\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[21]\tvalid_0's multi_logloss: 1.529\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[22]\tvalid_0's multi_logloss: 1.53661\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[23]\tvalid_0's multi_logloss: 1.54273\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[24]\tvalid_0's multi_logloss: 1.54716\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[25]\tvalid_0's multi_logloss: 1.55272\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[26]\tvalid_0's multi_logloss: 1.55723\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[27]\tvalid_0's multi_logloss: 1.5626\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[28]\tvalid_0's multi_logloss: 1.56789\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[29]\tvalid_0's multi_logloss: 1.57179\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30]\tvalid_0's multi_logloss: 1.5746\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[31]\tvalid_0's multi_logloss: 1.5782\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[32]\tvalid_0's multi_logloss: 1.58283\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 18\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 18\n",
      "[33]\tvalid_0's multi_logloss: 1.58581\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[34]\tvalid_0's multi_logloss: 1.58813\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[35]\tvalid_0's multi_logloss: 1.59183\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[36]\tvalid_0's multi_logloss: 1.59564\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[37]\tvalid_0's multi_logloss: 1.59906\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[38]\tvalid_0's multi_logloss: 1.6024\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 17\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[39]\tvalid_0's multi_logloss: 1.60522\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 16\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 17\n",
      "[40]\tvalid_0's multi_logloss: 1.60868\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[41]\tvalid_0's multi_logloss: 1.61261\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 17\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[42]\tvalid_0's multi_logloss: 1.61568\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[43]\tvalid_0's multi_logloss: 1.61877\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[44]\tvalid_0's multi_logloss: 1.62168\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[45]\tvalid_0's multi_logloss: 1.62427\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[46]\tvalid_0's multi_logloss: 1.62681\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 18\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[47]\tvalid_0's multi_logloss: 1.62971\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[48]\tvalid_0's multi_logloss: 1.6324\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[49]\tvalid_0's multi_logloss: 1.63446\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 18\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[50]\tvalid_0's multi_logloss: 1.63704\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 16\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 16\n",
      "[51]\tvalid_0's multi_logloss: 1.63873\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 17\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[52]\tvalid_0's multi_logloss: 1.64074\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 17\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 16\n",
      "[53]\tvalid_0's multi_logloss: 1.64314\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 16\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[54]\tvalid_0's multi_logloss: 1.64575\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 17\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[55]\tvalid_0's multi_logloss: 1.64772\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[56]\tvalid_0's multi_logloss: 1.64961\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 19\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[57]\tvalid_0's multi_logloss: 1.65172\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 17\n",
      "[58]\tvalid_0's multi_logloss: 1.65333\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 18\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[59]\tvalid_0's multi_logloss: 1.65609\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 16\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[60]\tvalid_0's multi_logloss: 1.65823\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[61]\tvalid_0's multi_logloss: 1.66002\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 17\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[62]\tvalid_0's multi_logloss: 1.66175\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[63]\tvalid_0's multi_logloss: 1.66364\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 17\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[64]\tvalid_0's multi_logloss: 1.66578\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 16\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 16\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[65]\tvalid_0's multi_logloss: 1.66724\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 16\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[66]\tvalid_0's multi_logloss: 1.67015\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[67]\tvalid_0's multi_logloss: 1.67244\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 18\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 21\n",
      "[68]\tvalid_0's multi_logloss: 1.67336\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 16\n",
      "[69]\tvalid_0's multi_logloss: 1.67527\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[70]\tvalid_0's multi_logloss: 1.67683\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[71]\tvalid_0's multi_logloss: 1.67854\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[72]\tvalid_0's multi_logloss: 1.68034\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 17\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[73]\tvalid_0's multi_logloss: 1.68247\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 16\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[74]\tvalid_0's multi_logloss: 1.68458\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[75]\tvalid_0's multi_logloss: 1.6864\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[76]\tvalid_0's multi_logloss: 1.68844\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 16\n",
      "[77]\tvalid_0's multi_logloss: 1.69003\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 18\n",
      "[78]\tvalid_0's multi_logloss: 1.69161\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 19\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[79]\tvalid_0's multi_logloss: 1.69394\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 17\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[80]\tvalid_0's multi_logloss: 1.69575\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[81]\tvalid_0's multi_logloss: 1.69848\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[82]\tvalid_0's multi_logloss: 1.70052\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[83]\tvalid_0's multi_logloss: 1.70243\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 17\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[84]\tvalid_0's multi_logloss: 1.70505\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[85]\tvalid_0's multi_logloss: 1.70628\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[86]\tvalid_0's multi_logloss: 1.70769\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[87]\tvalid_0's multi_logloss: 1.70959\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[88]\tvalid_0's multi_logloss: 1.71141\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[89]\tvalid_0's multi_logloss: 1.71323\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[90]\tvalid_0's multi_logloss: 1.7158\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[91]\tvalid_0's multi_logloss: 1.71753\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[92]\tvalid_0's multi_logloss: 1.71898\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 16\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 18\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[93]\tvalid_0's multi_logloss: 1.72244\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[94]\tvalid_0's multi_logloss: 1.72402\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 16\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 17\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[95]\tvalid_0's multi_logloss: 1.72578\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 16\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 17\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 19\n",
      "[96]\tvalid_0's multi_logloss: 1.72803\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 20\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 18\n",
      "[97]\tvalid_0's multi_logloss: 1.72991\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 16\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[98]\tvalid_0's multi_logloss: 1.73153\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 16\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 18\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[99]\tvalid_0's multi_logloss: 1.73376\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 16\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[100]\tvalid_0's multi_logloss: 1.73597\n",
      "log_loss 1.7359698049768681\n",
      "lightGBM_ac 0.29933333333333334\n",
      "MAE 0.05316983492812321\n",
      "lightGBM_score 0.6528700644413844\n",
      "--------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(verbose=2)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def lightGBM_model():\n",
    "    model = LGBMClassifier(verbose=2)\n",
    "    model.fit(X_train,y,eval_set=[(X_test,y)])##算法训练（加上交叉验证集）\n",
    "\n",
    "    pred = model.predict_proba(X_test) \n",
    "    MAE = 1/(1 + np.sum(np.absolute(np.eye(4)[y] - pred))/480)\n",
    "    lightGBM_score = 1/(1+10*MAE)\n",
    "    print('log_loss',log_loss(pd.get_dummies(y).values, pred))\n",
    "    print('lightGBM_ac',accuracy_score(y,np.argmax(pred,axis = 1)))\n",
    "    print('MAE',1/(1 + np.sum(np.absolute(np.eye(4)[y] - pred))/480))\n",
    "    print('lightGBM_score',1/(1+10*MAE))\n",
    "    print('--------------------------------')\n",
    "    return model\n",
    "lightGBM_model()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e1047852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.086698\n",
      "0:\tlearn: 1.3501150\ttotal: 43.4ms\tremaining: 43.4s\n",
      "1:\tlearn: 1.3194145\ttotal: 76.6ms\tremaining: 38.2s\n",
      "2:\tlearn: 1.2921707\ttotal: 110ms\tremaining: 36.5s\n",
      "3:\tlearn: 1.2733813\ttotal: 142ms\tremaining: 35.3s\n",
      "4:\tlearn: 1.2574871\ttotal: 171ms\tremaining: 34.1s\n",
      "5:\tlearn: 1.2423910\ttotal: 208ms\tremaining: 34.4s\n",
      "6:\tlearn: 1.2293868\ttotal: 238ms\tremaining: 33.8s\n",
      "7:\tlearn: 1.2181283\ttotal: 276ms\tremaining: 34.3s\n",
      "8:\tlearn: 1.2056083\ttotal: 298ms\tremaining: 32.8s\n",
      "9:\tlearn: 1.1953261\ttotal: 314ms\tremaining: 31s\n",
      "10:\tlearn: 1.1866064\ttotal: 327ms\tremaining: 29.4s\n",
      "11:\tlearn: 1.1790021\ttotal: 339ms\tremaining: 27.9s\n",
      "12:\tlearn: 1.1721870\ttotal: 350ms\tremaining: 26.6s\n",
      "13:\tlearn: 1.1661616\ttotal: 360ms\tremaining: 25.4s\n",
      "14:\tlearn: 1.1593437\ttotal: 372ms\tremaining: 24.4s\n",
      "15:\tlearn: 1.1538678\ttotal: 384ms\tremaining: 23.6s\n",
      "16:\tlearn: 1.1515550\ttotal: 392ms\tremaining: 22.7s\n",
      "17:\tlearn: 1.1456030\ttotal: 405ms\tremaining: 22.1s\n",
      "18:\tlearn: 1.1401308\ttotal: 417ms\tremaining: 21.5s\n",
      "19:\tlearn: 1.1371308\ttotal: 429ms\tremaining: 21s\n",
      "20:\tlearn: 1.1342344\ttotal: 440ms\tremaining: 20.5s\n",
      "21:\tlearn: 1.1306116\ttotal: 451ms\tremaining: 20s\n",
      "22:\tlearn: 1.1278409\ttotal: 462ms\tremaining: 19.6s\n",
      "23:\tlearn: 1.1251916\ttotal: 473ms\tremaining: 19.2s\n",
      "24:\tlearn: 1.1227123\ttotal: 484ms\tremaining: 18.9s\n",
      "25:\tlearn: 1.1215161\ttotal: 496ms\tremaining: 18.6s\n",
      "26:\tlearn: 1.1199279\ttotal: 507ms\tremaining: 18.3s\n",
      "27:\tlearn: 1.1169708\ttotal: 519ms\tremaining: 18s\n",
      "28:\tlearn: 1.1150204\ttotal: 530ms\tremaining: 17.7s\n",
      "29:\tlearn: 1.1138697\ttotal: 540ms\tremaining: 17.5s\n",
      "30:\tlearn: 1.1118630\ttotal: 552ms\tremaining: 17.3s\n",
      "31:\tlearn: 1.1098381\ttotal: 563ms\tremaining: 17s\n",
      "32:\tlearn: 1.1086532\ttotal: 573ms\tremaining: 16.8s\n",
      "33:\tlearn: 1.1064970\ttotal: 584ms\tremaining: 16.6s\n",
      "34:\tlearn: 1.1047290\ttotal: 595ms\tremaining: 16.4s\n",
      "35:\tlearn: 1.1030407\ttotal: 610ms\tremaining: 16.3s\n",
      "36:\tlearn: 1.1008921\ttotal: 622ms\tremaining: 16.2s\n",
      "37:\tlearn: 1.0995576\ttotal: 633ms\tremaining: 16s\n",
      "38:\tlearn: 1.0989255\ttotal: 644ms\tremaining: 15.9s\n",
      "39:\tlearn: 1.0972013\ttotal: 656ms\tremaining: 15.7s\n",
      "40:\tlearn: 1.0964359\ttotal: 667ms\tremaining: 15.6s\n",
      "41:\tlearn: 1.0952765\ttotal: 678ms\tremaining: 15.5s\n",
      "42:\tlearn: 1.0939799\ttotal: 689ms\tremaining: 15.3s\n",
      "43:\tlearn: 1.0922144\ttotal: 700ms\tremaining: 15.2s\n",
      "44:\tlearn: 1.0914422\ttotal: 713ms\tremaining: 15.1s\n",
      "45:\tlearn: 1.0899386\ttotal: 725ms\tremaining: 15s\n",
      "46:\tlearn: 1.0895397\ttotal: 738ms\tremaining: 15s\n",
      "47:\tlearn: 1.0889361\ttotal: 751ms\tremaining: 14.9s\n",
      "48:\tlearn: 1.0871502\ttotal: 763ms\tremaining: 14.8s\n",
      "49:\tlearn: 1.0862551\ttotal: 775ms\tremaining: 14.7s\n",
      "50:\tlearn: 1.0851920\ttotal: 787ms\tremaining: 14.6s\n",
      "51:\tlearn: 1.0838632\ttotal: 799ms\tremaining: 14.6s\n",
      "52:\tlearn: 1.0831707\ttotal: 811ms\tremaining: 14.5s\n",
      "53:\tlearn: 1.0824523\ttotal: 825ms\tremaining: 14.5s\n",
      "54:\tlearn: 1.0810992\ttotal: 837ms\tremaining: 14.4s\n",
      "55:\tlearn: 1.0806212\ttotal: 848ms\tremaining: 14.3s\n",
      "56:\tlearn: 1.0792331\ttotal: 860ms\tremaining: 14.2s\n",
      "57:\tlearn: 1.0775968\ttotal: 872ms\tremaining: 14.2s\n",
      "58:\tlearn: 1.0768272\ttotal: 884ms\tremaining: 14.1s\n",
      "59:\tlearn: 1.0761044\ttotal: 895ms\tremaining: 14s\n",
      "60:\tlearn: 1.0754220\ttotal: 906ms\tremaining: 13.9s\n",
      "61:\tlearn: 1.0743182\ttotal: 917ms\tremaining: 13.9s\n",
      "62:\tlearn: 1.0734897\ttotal: 929ms\tremaining: 13.8s\n",
      "63:\tlearn: 1.0727330\ttotal: 941ms\tremaining: 13.8s\n",
      "64:\tlearn: 1.0716665\ttotal: 953ms\tremaining: 13.7s\n",
      "65:\tlearn: 1.0714570\ttotal: 964ms\tremaining: 13.6s\n",
      "66:\tlearn: 1.0708433\ttotal: 975ms\tremaining: 13.6s\n",
      "67:\tlearn: 1.0698441\ttotal: 989ms\tremaining: 13.5s\n",
      "68:\tlearn: 1.0693526\ttotal: 1s\tremaining: 13.5s\n",
      "69:\tlearn: 1.0688200\ttotal: 1.02s\tremaining: 13.5s\n",
      "70:\tlearn: 1.0683245\ttotal: 1.03s\tremaining: 13.5s\n",
      "71:\tlearn: 1.0673289\ttotal: 1.04s\tremaining: 13.4s\n",
      "72:\tlearn: 1.0667337\ttotal: 1.05s\tremaining: 13.4s\n",
      "73:\tlearn: 1.0654252\ttotal: 1.06s\tremaining: 13.3s\n",
      "74:\tlearn: 1.0646375\ttotal: 1.08s\tremaining: 13.3s\n",
      "75:\tlearn: 1.0638709\ttotal: 1.09s\tremaining: 13.2s\n",
      "76:\tlearn: 1.0629511\ttotal: 1.1s\tremaining: 13.2s\n",
      "77:\tlearn: 1.0622000\ttotal: 1.11s\tremaining: 13.1s\n",
      "78:\tlearn: 1.0610429\ttotal: 1.12s\tremaining: 13.1s\n",
      "79:\tlearn: 1.0605394\ttotal: 1.13s\tremaining: 13s\n",
      "80:\tlearn: 1.0594719\ttotal: 1.15s\tremaining: 13s\n",
      "81:\tlearn: 1.0589817\ttotal: 1.16s\tremaining: 12.9s\n",
      "82:\tlearn: 1.0586849\ttotal: 1.17s\tremaining: 12.9s\n",
      "83:\tlearn: 1.0581746\ttotal: 1.18s\tremaining: 12.8s\n",
      "84:\tlearn: 1.0576460\ttotal: 1.19s\tremaining: 12.8s\n",
      "85:\tlearn: 1.0571433\ttotal: 1.2s\tremaining: 12.8s\n",
      "86:\tlearn: 1.0568256\ttotal: 1.22s\tremaining: 12.8s\n",
      "87:\tlearn: 1.0564341\ttotal: 1.23s\tremaining: 12.7s\n",
      "88:\tlearn: 1.0556594\ttotal: 1.24s\tremaining: 12.7s\n",
      "89:\tlearn: 1.0554029\ttotal: 1.26s\tremaining: 12.7s\n",
      "90:\tlearn: 1.0545083\ttotal: 1.27s\tremaining: 12.7s\n",
      "91:\tlearn: 1.0541176\ttotal: 1.28s\tremaining: 12.7s\n",
      "92:\tlearn: 1.0535567\ttotal: 1.29s\tremaining: 12.6s\n",
      "93:\tlearn: 1.0528695\ttotal: 1.31s\tremaining: 12.6s\n",
      "94:\tlearn: 1.0520488\ttotal: 1.32s\tremaining: 12.6s\n",
      "95:\tlearn: 1.0515282\ttotal: 1.33s\tremaining: 12.5s\n",
      "96:\tlearn: 1.0507448\ttotal: 1.34s\tremaining: 12.5s\n",
      "97:\tlearn: 1.0500894\ttotal: 1.35s\tremaining: 12.4s\n",
      "98:\tlearn: 1.0496349\ttotal: 1.36s\tremaining: 12.4s\n",
      "99:\tlearn: 1.0482468\ttotal: 1.38s\tremaining: 12.4s\n",
      "100:\tlearn: 1.0476749\ttotal: 1.39s\tremaining: 12.3s\n",
      "101:\tlearn: 1.0474944\ttotal: 1.4s\tremaining: 12.3s\n",
      "102:\tlearn: 1.0472113\ttotal: 1.41s\tremaining: 12.3s\n",
      "103:\tlearn: 1.0458331\ttotal: 1.42s\tremaining: 12.3s\n",
      "104:\tlearn: 1.0453904\ttotal: 1.43s\tremaining: 12.2s\n",
      "105:\tlearn: 1.0447464\ttotal: 1.45s\tremaining: 12.2s\n",
      "106:\tlearn: 1.0439841\ttotal: 1.46s\tremaining: 12.2s\n",
      "107:\tlearn: 1.0433209\ttotal: 1.47s\tremaining: 12.2s\n",
      "108:\tlearn: 1.0429504\ttotal: 1.48s\tremaining: 12.1s\n",
      "109:\tlearn: 1.0425497\ttotal: 1.49s\tremaining: 12.1s\n",
      "110:\tlearn: 1.0417333\ttotal: 1.5s\tremaining: 12.1s\n",
      "111:\tlearn: 1.0409550\ttotal: 1.52s\tremaining: 12s\n",
      "112:\tlearn: 1.0406557\ttotal: 1.53s\tremaining: 12s\n",
      "113:\tlearn: 1.0402210\ttotal: 1.54s\tremaining: 12s\n",
      "114:\tlearn: 1.0396252\ttotal: 1.55s\tremaining: 11.9s\n",
      "115:\tlearn: 1.0388435\ttotal: 1.56s\tremaining: 11.9s\n",
      "116:\tlearn: 1.0378809\ttotal: 1.57s\tremaining: 11.9s\n",
      "117:\tlearn: 1.0372791\ttotal: 1.59s\tremaining: 11.9s\n",
      "118:\tlearn: 1.0362959\ttotal: 1.6s\tremaining: 11.8s\n",
      "119:\tlearn: 1.0355978\ttotal: 1.61s\tremaining: 11.8s\n",
      "120:\tlearn: 1.0352425\ttotal: 1.63s\tremaining: 11.8s\n",
      "121:\tlearn: 1.0347137\ttotal: 1.64s\tremaining: 11.8s\n",
      "122:\tlearn: 1.0339592\ttotal: 1.65s\tremaining: 11.7s\n",
      "123:\tlearn: 1.0334617\ttotal: 1.66s\tremaining: 11.7s\n",
      "124:\tlearn: 1.0327295\ttotal: 1.67s\tremaining: 11.7s\n",
      "125:\tlearn: 1.0322448\ttotal: 1.68s\tremaining: 11.7s\n",
      "126:\tlearn: 1.0317507\ttotal: 1.69s\tremaining: 11.6s\n",
      "127:\tlearn: 1.0310804\ttotal: 1.71s\tremaining: 11.6s\n",
      "128:\tlearn: 1.0307558\ttotal: 1.72s\tremaining: 11.6s\n",
      "129:\tlearn: 1.0297844\ttotal: 1.73s\tremaining: 11.6s\n",
      "130:\tlearn: 1.0293398\ttotal: 1.74s\tremaining: 11.5s\n",
      "131:\tlearn: 1.0287049\ttotal: 1.75s\tremaining: 11.5s\n",
      "132:\tlearn: 1.0279832\ttotal: 1.76s\tremaining: 11.5s\n",
      "133:\tlearn: 1.0270794\ttotal: 1.78s\tremaining: 11.5s\n",
      "134:\tlearn: 1.0265464\ttotal: 1.79s\tremaining: 11.5s\n",
      "135:\tlearn: 1.0259975\ttotal: 1.8s\tremaining: 11.5s\n",
      "136:\tlearn: 1.0254469\ttotal: 1.82s\tremaining: 11.4s\n",
      "137:\tlearn: 1.0242520\ttotal: 1.83s\tremaining: 11.4s\n",
      "138:\tlearn: 1.0237312\ttotal: 1.84s\tremaining: 11.4s\n",
      "139:\tlearn: 1.0231676\ttotal: 1.85s\tremaining: 11.4s\n",
      "140:\tlearn: 1.0226320\ttotal: 1.86s\tremaining: 11.3s\n",
      "141:\tlearn: 1.0218515\ttotal: 1.87s\tremaining: 11.3s\n",
      "142:\tlearn: 1.0205361\ttotal: 1.89s\tremaining: 11.3s\n",
      "143:\tlearn: 1.0200217\ttotal: 1.9s\tremaining: 11.3s\n",
      "144:\tlearn: 1.0193478\ttotal: 1.91s\tremaining: 11.3s\n",
      "145:\tlearn: 1.0190074\ttotal: 1.92s\tremaining: 11.2s\n",
      "146:\tlearn: 1.0186394\ttotal: 1.93s\tremaining: 11.2s\n",
      "147:\tlearn: 1.0180915\ttotal: 1.94s\tremaining: 11.2s\n",
      "148:\tlearn: 1.0175847\ttotal: 1.96s\tremaining: 11.2s\n",
      "149:\tlearn: 1.0171954\ttotal: 1.97s\tremaining: 11.2s\n",
      "150:\tlearn: 1.0166842\ttotal: 1.99s\tremaining: 11.2s\n",
      "151:\tlearn: 1.0160422\ttotal: 2s\tremaining: 11.2s\n",
      "152:\tlearn: 1.0153390\ttotal: 2.01s\tremaining: 11.1s\n",
      "153:\tlearn: 1.0149765\ttotal: 2.02s\tremaining: 11.1s\n",
      "154:\tlearn: 1.0143756\ttotal: 2.04s\tremaining: 11.1s\n",
      "155:\tlearn: 1.0137777\ttotal: 2.05s\tremaining: 11.1s\n",
      "156:\tlearn: 1.0134363\ttotal: 2.06s\tremaining: 11.1s\n",
      "157:\tlearn: 1.0130040\ttotal: 2.07s\tremaining: 11s\n",
      "158:\tlearn: 1.0123247\ttotal: 2.08s\tremaining: 11s\n",
      "159:\tlearn: 1.0114792\ttotal: 2.09s\tremaining: 11s\n",
      "160:\tlearn: 1.0109395\ttotal: 2.1s\tremaining: 11s\n",
      "161:\tlearn: 1.0104307\ttotal: 2.12s\tremaining: 10.9s\n",
      "162:\tlearn: 1.0097514\ttotal: 2.13s\tremaining: 10.9s\n",
      "163:\tlearn: 1.0087030\ttotal: 2.14s\tremaining: 10.9s\n",
      "164:\tlearn: 1.0079816\ttotal: 2.15s\tremaining: 10.9s\n",
      "165:\tlearn: 1.0076120\ttotal: 2.16s\tremaining: 10.8s\n",
      "166:\tlearn: 1.0073577\ttotal: 2.17s\tremaining: 10.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167:\tlearn: 1.0069355\ttotal: 2.18s\tremaining: 10.8s\n",
      "168:\tlearn: 1.0063341\ttotal: 2.19s\tremaining: 10.8s\n",
      "169:\tlearn: 1.0053767\ttotal: 2.21s\tremaining: 10.8s\n",
      "170:\tlearn: 1.0048867\ttotal: 2.22s\tremaining: 10.8s\n",
      "171:\tlearn: 1.0045577\ttotal: 2.23s\tremaining: 10.8s\n",
      "172:\tlearn: 1.0041208\ttotal: 2.24s\tremaining: 10.7s\n",
      "173:\tlearn: 1.0033412\ttotal: 2.26s\tremaining: 10.7s\n",
      "174:\tlearn: 1.0028074\ttotal: 2.27s\tremaining: 10.7s\n",
      "175:\tlearn: 1.0021444\ttotal: 2.28s\tremaining: 10.7s\n",
      "176:\tlearn: 1.0015294\ttotal: 2.29s\tremaining: 10.7s\n",
      "177:\tlearn: 1.0009350\ttotal: 2.3s\tremaining: 10.6s\n",
      "178:\tlearn: 1.0004260\ttotal: 2.31s\tremaining: 10.6s\n",
      "179:\tlearn: 0.9998323\ttotal: 2.33s\tremaining: 10.6s\n",
      "180:\tlearn: 0.9991080\ttotal: 2.34s\tremaining: 10.6s\n",
      "181:\tlearn: 0.9987299\ttotal: 2.35s\tremaining: 10.6s\n",
      "182:\tlearn: 0.9980079\ttotal: 2.36s\tremaining: 10.5s\n",
      "183:\tlearn: 0.9973932\ttotal: 2.37s\tremaining: 10.5s\n",
      "184:\tlearn: 0.9967220\ttotal: 2.38s\tremaining: 10.5s\n",
      "185:\tlearn: 0.9963910\ttotal: 2.4s\tremaining: 10.5s\n",
      "186:\tlearn: 0.9956707\ttotal: 2.41s\tremaining: 10.5s\n",
      "187:\tlearn: 0.9953332\ttotal: 2.42s\tremaining: 10.4s\n",
      "188:\tlearn: 0.9945255\ttotal: 2.43s\tremaining: 10.4s\n",
      "189:\tlearn: 0.9942258\ttotal: 2.44s\tremaining: 10.4s\n",
      "190:\tlearn: 0.9934103\ttotal: 2.45s\tremaining: 10.4s\n",
      "191:\tlearn: 0.9930814\ttotal: 2.46s\tremaining: 10.4s\n",
      "192:\tlearn: 0.9927083\ttotal: 2.48s\tremaining: 10.4s\n",
      "193:\tlearn: 0.9922246\ttotal: 2.49s\tremaining: 10.3s\n",
      "194:\tlearn: 0.9920019\ttotal: 2.5s\tremaining: 10.3s\n",
      "195:\tlearn: 0.9912871\ttotal: 2.51s\tremaining: 10.3s\n",
      "196:\tlearn: 0.9905328\ttotal: 2.52s\tremaining: 10.3s\n",
      "197:\tlearn: 0.9902137\ttotal: 2.54s\tremaining: 10.3s\n",
      "198:\tlearn: 0.9895231\ttotal: 2.55s\tremaining: 10.3s\n",
      "199:\tlearn: 0.9891731\ttotal: 2.56s\tremaining: 10.2s\n",
      "200:\tlearn: 0.9881999\ttotal: 2.57s\tremaining: 10.2s\n",
      "201:\tlearn: 0.9877329\ttotal: 2.58s\tremaining: 10.2s\n",
      "202:\tlearn: 0.9870134\ttotal: 2.6s\tremaining: 10.2s\n",
      "203:\tlearn: 0.9863783\ttotal: 2.61s\tremaining: 10.2s\n",
      "204:\tlearn: 0.9858301\ttotal: 2.62s\tremaining: 10.2s\n",
      "205:\tlearn: 0.9854008\ttotal: 2.63s\tremaining: 10.1s\n",
      "206:\tlearn: 0.9850817\ttotal: 2.64s\tremaining: 10.1s\n",
      "207:\tlearn: 0.9846008\ttotal: 2.65s\tremaining: 10.1s\n",
      "208:\tlearn: 0.9841081\ttotal: 2.67s\tremaining: 10.1s\n",
      "209:\tlearn: 0.9836738\ttotal: 2.68s\tremaining: 10.1s\n",
      "210:\tlearn: 0.9832480\ttotal: 2.69s\tremaining: 10.1s\n",
      "211:\tlearn: 0.9830264\ttotal: 2.7s\tremaining: 10s\n",
      "212:\tlearn: 0.9826077\ttotal: 2.71s\tremaining: 10s\n",
      "213:\tlearn: 0.9818254\ttotal: 2.72s\tremaining: 10s\n",
      "214:\tlearn: 0.9813814\ttotal: 2.73s\tremaining: 9.98s\n",
      "215:\tlearn: 0.9810914\ttotal: 2.75s\tremaining: 9.97s\n",
      "216:\tlearn: 0.9806550\ttotal: 2.76s\tremaining: 9.95s\n",
      "217:\tlearn: 0.9803498\ttotal: 2.77s\tremaining: 9.94s\n",
      "218:\tlearn: 0.9798466\ttotal: 2.78s\tremaining: 9.92s\n",
      "219:\tlearn: 0.9795361\ttotal: 2.79s\tremaining: 9.9s\n",
      "220:\tlearn: 0.9791103\ttotal: 2.81s\tremaining: 9.89s\n",
      "221:\tlearn: 0.9786700\ttotal: 2.82s\tremaining: 9.87s\n",
      "222:\tlearn: 0.9782810\ttotal: 2.83s\tremaining: 9.85s\n",
      "223:\tlearn: 0.9777377\ttotal: 2.84s\tremaining: 9.84s\n",
      "224:\tlearn: 0.9771117\ttotal: 2.85s\tremaining: 9.82s\n",
      "225:\tlearn: 0.9763062\ttotal: 2.86s\tremaining: 9.81s\n",
      "226:\tlearn: 0.9759155\ttotal: 2.88s\tremaining: 9.79s\n",
      "227:\tlearn: 0.9753616\ttotal: 2.89s\tremaining: 9.78s\n",
      "228:\tlearn: 0.9751202\ttotal: 2.9s\tremaining: 9.76s\n",
      "229:\tlearn: 0.9748184\ttotal: 2.91s\tremaining: 9.74s\n",
      "230:\tlearn: 0.9744342\ttotal: 2.92s\tremaining: 9.72s\n",
      "231:\tlearn: 0.9739906\ttotal: 2.96s\tremaining: 9.79s\n",
      "232:\tlearn: 0.9733029\ttotal: 3.01s\tremaining: 9.91s\n",
      "233:\tlearn: 0.9729912\ttotal: 3.04s\tremaining: 9.94s\n",
      "234:\tlearn: 0.9723246\ttotal: 3.05s\tremaining: 9.93s\n",
      "235:\tlearn: 0.9718259\ttotal: 3.06s\tremaining: 9.92s\n",
      "236:\tlearn: 0.9715031\ttotal: 3.07s\tremaining: 9.9s\n",
      "237:\tlearn: 0.9713187\ttotal: 3.08s\tremaining: 9.88s\n",
      "238:\tlearn: 0.9708874\ttotal: 3.1s\tremaining: 9.86s\n",
      "239:\tlearn: 0.9702269\ttotal: 3.11s\tremaining: 9.85s\n",
      "240:\tlearn: 0.9699917\ttotal: 3.12s\tremaining: 9.82s\n",
      "241:\tlearn: 0.9697123\ttotal: 3.13s\tremaining: 9.8s\n",
      "242:\tlearn: 0.9694585\ttotal: 3.14s\tremaining: 9.79s\n",
      "243:\tlearn: 0.9690756\ttotal: 3.15s\tremaining: 9.77s\n",
      "244:\tlearn: 0.9686350\ttotal: 3.16s\tremaining: 9.75s\n",
      "245:\tlearn: 0.9680925\ttotal: 3.17s\tremaining: 9.73s\n",
      "246:\tlearn: 0.9677461\ttotal: 3.19s\tremaining: 9.71s\n",
      "247:\tlearn: 0.9672442\ttotal: 3.2s\tremaining: 9.69s\n",
      "248:\tlearn: 0.9665131\ttotal: 3.22s\tremaining: 9.7s\n",
      "249:\tlearn: 0.9661486\ttotal: 3.23s\tremaining: 9.7s\n",
      "250:\tlearn: 0.9659111\ttotal: 3.24s\tremaining: 9.68s\n",
      "251:\tlearn: 0.9652738\ttotal: 3.26s\tremaining: 9.66s\n",
      "252:\tlearn: 0.9646611\ttotal: 3.27s\tremaining: 9.65s\n",
      "253:\tlearn: 0.9644472\ttotal: 3.28s\tremaining: 9.63s\n",
      "254:\tlearn: 0.9640566\ttotal: 3.29s\tremaining: 9.61s\n",
      "255:\tlearn: 0.9638358\ttotal: 3.3s\tremaining: 9.6s\n",
      "256:\tlearn: 0.9631627\ttotal: 3.31s\tremaining: 9.58s\n",
      "257:\tlearn: 0.9625919\ttotal: 3.33s\tremaining: 9.57s\n",
      "258:\tlearn: 0.9621545\ttotal: 3.34s\tremaining: 9.55s\n",
      "259:\tlearn: 0.9617838\ttotal: 3.35s\tremaining: 9.53s\n",
      "260:\tlearn: 0.9613430\ttotal: 3.36s\tremaining: 9.51s\n",
      "261:\tlearn: 0.9610488\ttotal: 3.37s\tremaining: 9.5s\n",
      "262:\tlearn: 0.9607512\ttotal: 3.38s\tremaining: 9.48s\n",
      "263:\tlearn: 0.9602875\ttotal: 3.39s\tremaining: 9.46s\n",
      "264:\tlearn: 0.9597927\ttotal: 3.41s\tremaining: 9.45s\n",
      "265:\tlearn: 0.9590705\ttotal: 3.42s\tremaining: 9.43s\n",
      "266:\tlearn: 0.9584905\ttotal: 3.43s\tremaining: 9.42s\n",
      "267:\tlearn: 0.9582948\ttotal: 3.44s\tremaining: 9.4s\n",
      "268:\tlearn: 0.9578088\ttotal: 3.45s\tremaining: 9.39s\n",
      "269:\tlearn: 0.9571869\ttotal: 3.47s\tremaining: 9.37s\n",
      "270:\tlearn: 0.9566687\ttotal: 3.48s\tremaining: 9.36s\n",
      "271:\tlearn: 0.9559900\ttotal: 3.49s\tremaining: 9.34s\n",
      "272:\tlearn: 0.9557761\ttotal: 3.5s\tremaining: 9.32s\n",
      "273:\tlearn: 0.9553136\ttotal: 3.51s\tremaining: 9.3s\n",
      "274:\tlearn: 0.9546725\ttotal: 3.52s\tremaining: 9.29s\n",
      "275:\tlearn: 0.9541053\ttotal: 3.54s\tremaining: 9.28s\n",
      "276:\tlearn: 0.9535597\ttotal: 3.55s\tremaining: 9.26s\n",
      "277:\tlearn: 0.9532080\ttotal: 3.56s\tremaining: 9.24s\n",
      "278:\tlearn: 0.9529985\ttotal: 3.57s\tremaining: 9.22s\n",
      "279:\tlearn: 0.9521178\ttotal: 3.58s\tremaining: 9.21s\n",
      "280:\tlearn: 0.9513562\ttotal: 3.59s\tremaining: 9.19s\n",
      "281:\tlearn: 0.9511238\ttotal: 3.6s\tremaining: 9.18s\n",
      "282:\tlearn: 0.9507346\ttotal: 3.62s\tremaining: 9.16s\n",
      "283:\tlearn: 0.9503065\ttotal: 3.63s\tremaining: 9.15s\n",
      "284:\tlearn: 0.9499582\ttotal: 3.64s\tremaining: 9.13s\n",
      "285:\tlearn: 0.9497480\ttotal: 3.65s\tremaining: 9.12s\n",
      "286:\tlearn: 0.9495106\ttotal: 3.66s\tremaining: 9.1s\n",
      "287:\tlearn: 0.9488694\ttotal: 3.67s\tremaining: 9.08s\n",
      "288:\tlearn: 0.9480585\ttotal: 3.68s\tremaining: 9.06s\n",
      "289:\tlearn: 0.9476572\ttotal: 3.7s\tremaining: 9.05s\n",
      "290:\tlearn: 0.9471631\ttotal: 3.71s\tremaining: 9.04s\n",
      "291:\tlearn: 0.9468364\ttotal: 3.72s\tremaining: 9.02s\n",
      "292:\tlearn: 0.9463929\ttotal: 3.73s\tremaining: 9.01s\n",
      "293:\tlearn: 0.9456821\ttotal: 3.75s\tremaining: 9s\n",
      "294:\tlearn: 0.9454863\ttotal: 3.76s\tremaining: 8.99s\n",
      "295:\tlearn: 0.9453619\ttotal: 3.77s\tremaining: 8.97s\n",
      "296:\tlearn: 0.9447867\ttotal: 3.79s\tremaining: 8.96s\n",
      "297:\tlearn: 0.9442682\ttotal: 3.8s\tremaining: 8.95s\n",
      "298:\tlearn: 0.9440624\ttotal: 3.81s\tremaining: 8.94s\n",
      "299:\tlearn: 0.9435540\ttotal: 3.83s\tremaining: 8.93s\n",
      "300:\tlearn: 0.9429036\ttotal: 3.84s\tremaining: 8.92s\n",
      "301:\tlearn: 0.9425791\ttotal: 3.85s\tremaining: 8.91s\n",
      "302:\tlearn: 0.9422042\ttotal: 3.87s\tremaining: 8.9s\n",
      "303:\tlearn: 0.9418078\ttotal: 3.88s\tremaining: 8.89s\n",
      "304:\tlearn: 0.9414488\ttotal: 3.9s\tremaining: 8.88s\n",
      "305:\tlearn: 0.9411579\ttotal: 3.91s\tremaining: 8.86s\n",
      "306:\tlearn: 0.9406351\ttotal: 3.92s\tremaining: 8.86s\n",
      "307:\tlearn: 0.9403850\ttotal: 3.94s\tremaining: 8.85s\n",
      "308:\tlearn: 0.9401635\ttotal: 3.95s\tremaining: 8.84s\n",
      "309:\tlearn: 0.9397311\ttotal: 3.97s\tremaining: 8.83s\n",
      "310:\tlearn: 0.9391544\ttotal: 3.98s\tremaining: 8.83s\n",
      "311:\tlearn: 0.9385705\ttotal: 4s\tremaining: 8.81s\n",
      "312:\tlearn: 0.9383389\ttotal: 4.01s\tremaining: 8.8s\n",
      "313:\tlearn: 0.9379826\ttotal: 4.03s\tremaining: 8.79s\n",
      "314:\tlearn: 0.9375791\ttotal: 4.04s\tremaining: 8.78s\n",
      "315:\tlearn: 0.9372076\ttotal: 4.05s\tremaining: 8.77s\n",
      "316:\tlearn: 0.9368876\ttotal: 4.07s\tremaining: 8.76s\n",
      "317:\tlearn: 0.9366782\ttotal: 4.08s\tremaining: 8.75s\n",
      "318:\tlearn: 0.9363901\ttotal: 4.09s\tremaining: 8.73s\n",
      "319:\tlearn: 0.9359793\ttotal: 4.1s\tremaining: 8.72s\n",
      "320:\tlearn: 0.9356433\ttotal: 4.12s\tremaining: 8.71s\n",
      "321:\tlearn: 0.9353152\ttotal: 4.13s\tremaining: 8.69s\n",
      "322:\tlearn: 0.9351521\ttotal: 4.14s\tremaining: 8.68s\n",
      "323:\tlearn: 0.9348800\ttotal: 4.15s\tremaining: 8.66s\n",
      "324:\tlearn: 0.9344704\ttotal: 4.17s\tremaining: 8.65s\n",
      "325:\tlearn: 0.9342510\ttotal: 4.18s\tremaining: 8.64s\n",
      "326:\tlearn: 0.9338734\ttotal: 4.19s\tremaining: 8.62s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "327:\tlearn: 0.9333799\ttotal: 4.2s\tremaining: 8.61s\n",
      "328:\tlearn: 0.9331997\ttotal: 4.22s\tremaining: 8.6s\n",
      "329:\tlearn: 0.9326164\ttotal: 4.23s\tremaining: 8.59s\n",
      "330:\tlearn: 0.9322901\ttotal: 4.24s\tremaining: 8.57s\n",
      "331:\tlearn: 0.9320056\ttotal: 4.25s\tremaining: 8.56s\n",
      "332:\tlearn: 0.9315114\ttotal: 4.27s\tremaining: 8.54s\n",
      "333:\tlearn: 0.9309525\ttotal: 4.28s\tremaining: 8.53s\n",
      "334:\tlearn: 0.9305292\ttotal: 4.29s\tremaining: 8.52s\n",
      "335:\tlearn: 0.9302399\ttotal: 4.3s\tremaining: 8.5s\n",
      "336:\tlearn: 0.9299094\ttotal: 4.31s\tremaining: 8.48s\n",
      "337:\tlearn: 0.9294280\ttotal: 4.32s\tremaining: 8.47s\n",
      "338:\tlearn: 0.9290969\ttotal: 4.34s\tremaining: 8.45s\n",
      "339:\tlearn: 0.9283432\ttotal: 4.35s\tremaining: 8.44s\n",
      "340:\tlearn: 0.9279777\ttotal: 4.36s\tremaining: 8.43s\n",
      "341:\tlearn: 0.9275027\ttotal: 4.38s\tremaining: 8.42s\n",
      "342:\tlearn: 0.9269360\ttotal: 4.39s\tremaining: 8.4s\n",
      "343:\tlearn: 0.9263027\ttotal: 4.4s\tremaining: 8.39s\n",
      "344:\tlearn: 0.9260953\ttotal: 4.41s\tremaining: 8.38s\n",
      "345:\tlearn: 0.9257061\ttotal: 4.42s\tremaining: 8.36s\n",
      "346:\tlearn: 0.9252468\ttotal: 4.44s\tremaining: 8.35s\n",
      "347:\tlearn: 0.9247704\ttotal: 4.45s\tremaining: 8.34s\n",
      "348:\tlearn: 0.9243336\ttotal: 4.46s\tremaining: 8.32s\n",
      "349:\tlearn: 0.9241694\ttotal: 4.47s\tremaining: 8.31s\n",
      "350:\tlearn: 0.9238388\ttotal: 4.49s\tremaining: 8.29s\n",
      "351:\tlearn: 0.9231538\ttotal: 4.5s\tremaining: 8.28s\n",
      "352:\tlearn: 0.9229533\ttotal: 4.51s\tremaining: 8.27s\n",
      "353:\tlearn: 0.9226641\ttotal: 4.52s\tremaining: 8.26s\n",
      "354:\tlearn: 0.9222826\ttotal: 4.54s\tremaining: 8.24s\n",
      "355:\tlearn: 0.9218317\ttotal: 4.55s\tremaining: 8.23s\n",
      "356:\tlearn: 0.9215681\ttotal: 4.56s\tremaining: 8.21s\n",
      "357:\tlearn: 0.9213999\ttotal: 4.57s\tremaining: 8.2s\n",
      "358:\tlearn: 0.9207608\ttotal: 4.58s\tremaining: 8.19s\n",
      "359:\tlearn: 0.9205558\ttotal: 4.6s\tremaining: 8.17s\n",
      "360:\tlearn: 0.9202430\ttotal: 4.61s\tremaining: 8.16s\n",
      "361:\tlearn: 0.9200129\ttotal: 4.62s\tremaining: 8.14s\n",
      "362:\tlearn: 0.9197130\ttotal: 4.63s\tremaining: 8.13s\n",
      "363:\tlearn: 0.9194446\ttotal: 4.64s\tremaining: 8.12s\n",
      "364:\tlearn: 0.9192483\ttotal: 4.66s\tremaining: 8.1s\n",
      "365:\tlearn: 0.9186905\ttotal: 4.67s\tremaining: 8.09s\n",
      "366:\tlearn: 0.9184249\ttotal: 4.68s\tremaining: 8.07s\n",
      "367:\tlearn: 0.9181483\ttotal: 4.69s\tremaining: 8.06s\n",
      "368:\tlearn: 0.9178390\ttotal: 4.7s\tremaining: 8.04s\n",
      "369:\tlearn: 0.9172221\ttotal: 4.71s\tremaining: 8.03s\n",
      "370:\tlearn: 0.9169536\ttotal: 4.73s\tremaining: 8.01s\n",
      "371:\tlearn: 0.9164712\ttotal: 4.74s\tremaining: 8s\n",
      "372:\tlearn: 0.9161263\ttotal: 4.75s\tremaining: 7.99s\n",
      "373:\tlearn: 0.9158534\ttotal: 4.76s\tremaining: 7.98s\n",
      "374:\tlearn: 0.9156664\ttotal: 4.78s\tremaining: 7.96s\n",
      "375:\tlearn: 0.9152978\ttotal: 4.79s\tremaining: 7.95s\n",
      "376:\tlearn: 0.9149118\ttotal: 4.8s\tremaining: 7.93s\n",
      "377:\tlearn: 0.9146417\ttotal: 4.81s\tremaining: 7.92s\n",
      "378:\tlearn: 0.9144621\ttotal: 4.82s\tremaining: 7.9s\n",
      "379:\tlearn: 0.9140921\ttotal: 4.83s\tremaining: 7.89s\n",
      "380:\tlearn: 0.9137490\ttotal: 4.85s\tremaining: 7.88s\n",
      "381:\tlearn: 0.9134921\ttotal: 4.86s\tremaining: 7.86s\n",
      "382:\tlearn: 0.9130638\ttotal: 4.87s\tremaining: 7.85s\n",
      "383:\tlearn: 0.9127879\ttotal: 4.88s\tremaining: 7.83s\n",
      "384:\tlearn: 0.9122262\ttotal: 4.89s\tremaining: 7.82s\n",
      "385:\tlearn: 0.9119896\ttotal: 4.91s\tremaining: 7.8s\n",
      "386:\tlearn: 0.9113533\ttotal: 4.92s\tremaining: 7.79s\n",
      "387:\tlearn: 0.9110815\ttotal: 4.93s\tremaining: 7.78s\n",
      "388:\tlearn: 0.9108553\ttotal: 4.95s\tremaining: 7.77s\n",
      "389:\tlearn: 0.9104787\ttotal: 4.96s\tremaining: 7.75s\n",
      "390:\tlearn: 0.9102611\ttotal: 4.97s\tremaining: 7.74s\n",
      "391:\tlearn: 0.9097054\ttotal: 4.98s\tremaining: 7.72s\n",
      "392:\tlearn: 0.9094063\ttotal: 4.99s\tremaining: 7.71s\n",
      "393:\tlearn: 0.9090993\ttotal: 5s\tremaining: 7.7s\n",
      "394:\tlearn: 0.9085744\ttotal: 5.01s\tremaining: 7.68s\n",
      "395:\tlearn: 0.9081779\ttotal: 5.03s\tremaining: 7.67s\n",
      "396:\tlearn: 0.9078480\ttotal: 5.04s\tremaining: 7.65s\n",
      "397:\tlearn: 0.9075062\ttotal: 5.05s\tremaining: 7.64s\n",
      "398:\tlearn: 0.9071694\ttotal: 5.06s\tremaining: 7.62s\n",
      "399:\tlearn: 0.9068419\ttotal: 5.07s\tremaining: 7.61s\n",
      "400:\tlearn: 0.9066473\ttotal: 5.08s\tremaining: 7.59s\n",
      "401:\tlearn: 0.9062756\ttotal: 5.09s\tremaining: 7.58s\n",
      "402:\tlearn: 0.9060897\ttotal: 5.1s\tremaining: 7.56s\n",
      "403:\tlearn: 0.9058955\ttotal: 5.11s\tremaining: 7.54s\n",
      "404:\tlearn: 0.9056234\ttotal: 5.13s\tremaining: 7.53s\n",
      "405:\tlearn: 0.9050433\ttotal: 5.14s\tremaining: 7.52s\n",
      "406:\tlearn: 0.9046483\ttotal: 5.15s\tremaining: 7.51s\n",
      "407:\tlearn: 0.9042225\ttotal: 5.16s\tremaining: 7.49s\n",
      "408:\tlearn: 0.9038878\ttotal: 5.18s\tremaining: 7.48s\n",
      "409:\tlearn: 0.9036076\ttotal: 5.19s\tremaining: 7.47s\n",
      "410:\tlearn: 0.9032428\ttotal: 5.2s\tremaining: 7.45s\n",
      "411:\tlearn: 0.9028676\ttotal: 5.21s\tremaining: 7.44s\n",
      "412:\tlearn: 0.9025804\ttotal: 5.23s\tremaining: 7.43s\n",
      "413:\tlearn: 0.9021307\ttotal: 5.24s\tremaining: 7.42s\n",
      "414:\tlearn: 0.9018124\ttotal: 5.25s\tremaining: 7.41s\n",
      "415:\tlearn: 0.9015268\ttotal: 5.27s\tremaining: 7.39s\n",
      "416:\tlearn: 0.9010002\ttotal: 5.28s\tremaining: 7.38s\n",
      "417:\tlearn: 0.9006084\ttotal: 5.3s\tremaining: 7.37s\n",
      "418:\tlearn: 0.9003889\ttotal: 5.31s\tremaining: 7.36s\n",
      "419:\tlearn: 0.9001141\ttotal: 5.32s\tremaining: 7.35s\n",
      "420:\tlearn: 0.8996002\ttotal: 5.34s\tremaining: 7.34s\n",
      "421:\tlearn: 0.8994456\ttotal: 5.35s\tremaining: 7.33s\n",
      "422:\tlearn: 0.8988271\ttotal: 5.36s\tremaining: 7.32s\n",
      "423:\tlearn: 0.8985346\ttotal: 5.38s\tremaining: 7.3s\n",
      "424:\tlearn: 0.8981440\ttotal: 5.39s\tremaining: 7.3s\n",
      "425:\tlearn: 0.8977185\ttotal: 5.41s\tremaining: 7.29s\n",
      "426:\tlearn: 0.8975271\ttotal: 5.42s\tremaining: 7.27s\n",
      "427:\tlearn: 0.8972720\ttotal: 5.43s\tremaining: 7.26s\n",
      "428:\tlearn: 0.8970707\ttotal: 5.45s\tremaining: 7.25s\n",
      "429:\tlearn: 0.8963242\ttotal: 5.47s\tremaining: 7.25s\n",
      "430:\tlearn: 0.8957406\ttotal: 5.48s\tremaining: 7.24s\n",
      "431:\tlearn: 0.8952912\ttotal: 5.5s\tremaining: 7.23s\n",
      "432:\tlearn: 0.8949982\ttotal: 5.51s\tremaining: 7.22s\n",
      "433:\tlearn: 0.8948259\ttotal: 5.52s\tremaining: 7.2s\n",
      "434:\tlearn: 0.8945542\ttotal: 5.54s\tremaining: 7.19s\n",
      "435:\tlearn: 0.8941269\ttotal: 5.55s\tremaining: 7.18s\n",
      "436:\tlearn: 0.8935525\ttotal: 5.57s\tremaining: 7.17s\n",
      "437:\tlearn: 0.8931620\ttotal: 5.58s\tremaining: 7.16s\n",
      "438:\tlearn: 0.8928785\ttotal: 5.59s\tremaining: 7.15s\n",
      "439:\tlearn: 0.8925937\ttotal: 5.61s\tremaining: 7.14s\n",
      "440:\tlearn: 0.8921993\ttotal: 5.62s\tremaining: 7.13s\n",
      "441:\tlearn: 0.8918398\ttotal: 5.63s\tremaining: 7.11s\n",
      "442:\tlearn: 0.8914821\ttotal: 5.65s\tremaining: 7.1s\n",
      "443:\tlearn: 0.8910780\ttotal: 5.66s\tremaining: 7.09s\n",
      "444:\tlearn: 0.8908020\ttotal: 5.67s\tremaining: 7.08s\n",
      "445:\tlearn: 0.8902546\ttotal: 5.69s\tremaining: 7.07s\n",
      "446:\tlearn: 0.8898454\ttotal: 5.7s\tremaining: 7.05s\n",
      "447:\tlearn: 0.8896065\ttotal: 5.71s\tremaining: 7.04s\n",
      "448:\tlearn: 0.8892667\ttotal: 5.72s\tremaining: 7.03s\n",
      "449:\tlearn: 0.8887765\ttotal: 5.74s\tremaining: 7.01s\n",
      "450:\tlearn: 0.8883311\ttotal: 5.75s\tremaining: 7s\n",
      "451:\tlearn: 0.8877888\ttotal: 5.76s\tremaining: 6.99s\n",
      "452:\tlearn: 0.8875297\ttotal: 5.78s\tremaining: 6.98s\n",
      "453:\tlearn: 0.8872730\ttotal: 5.79s\tremaining: 6.96s\n",
      "454:\tlearn: 0.8867502\ttotal: 5.8s\tremaining: 6.95s\n",
      "455:\tlearn: 0.8862030\ttotal: 5.82s\tremaining: 6.94s\n",
      "456:\tlearn: 0.8857106\ttotal: 5.83s\tremaining: 6.93s\n",
      "457:\tlearn: 0.8855702\ttotal: 5.84s\tremaining: 6.91s\n",
      "458:\tlearn: 0.8853316\ttotal: 5.85s\tremaining: 6.9s\n",
      "459:\tlearn: 0.8850945\ttotal: 5.86s\tremaining: 6.88s\n",
      "460:\tlearn: 0.8847172\ttotal: 5.88s\tremaining: 6.87s\n",
      "461:\tlearn: 0.8844380\ttotal: 5.89s\tremaining: 6.86s\n",
      "462:\tlearn: 0.8842307\ttotal: 5.9s\tremaining: 6.85s\n",
      "463:\tlearn: 0.8840234\ttotal: 5.92s\tremaining: 6.83s\n",
      "464:\tlearn: 0.8837676\ttotal: 5.93s\tremaining: 6.82s\n",
      "465:\tlearn: 0.8835058\ttotal: 5.94s\tremaining: 6.81s\n",
      "466:\tlearn: 0.8832711\ttotal: 5.95s\tremaining: 6.79s\n",
      "467:\tlearn: 0.8829042\ttotal: 5.96s\tremaining: 6.78s\n",
      "468:\tlearn: 0.8823292\ttotal: 5.98s\tremaining: 6.77s\n",
      "469:\tlearn: 0.8820916\ttotal: 5.99s\tremaining: 6.76s\n",
      "470:\tlearn: 0.8815564\ttotal: 6s\tremaining: 6.74s\n",
      "471:\tlearn: 0.8812728\ttotal: 6.02s\tremaining: 6.73s\n",
      "472:\tlearn: 0.8810937\ttotal: 6.03s\tremaining: 6.71s\n",
      "473:\tlearn: 0.8806812\ttotal: 6.04s\tremaining: 6.7s\n",
      "474:\tlearn: 0.8801618\ttotal: 6.05s\tremaining: 6.69s\n",
      "475:\tlearn: 0.8799768\ttotal: 6.06s\tremaining: 6.67s\n",
      "476:\tlearn: 0.8795416\ttotal: 6.08s\tremaining: 6.66s\n",
      "477:\tlearn: 0.8792051\ttotal: 6.09s\tremaining: 6.65s\n",
      "478:\tlearn: 0.8790006\ttotal: 6.1s\tremaining: 6.63s\n",
      "479:\tlearn: 0.8786621\ttotal: 6.11s\tremaining: 6.62s\n",
      "480:\tlearn: 0.8783394\ttotal: 6.12s\tremaining: 6.61s\n",
      "481:\tlearn: 0.8776305\ttotal: 6.13s\tremaining: 6.59s\n",
      "482:\tlearn: 0.8771591\ttotal: 6.15s\tremaining: 6.58s\n",
      "483:\tlearn: 0.8766870\ttotal: 6.16s\tremaining: 6.57s\n",
      "484:\tlearn: 0.8762760\ttotal: 6.17s\tremaining: 6.55s\n",
      "485:\tlearn: 0.8758354\ttotal: 6.18s\tremaining: 6.54s\n",
      "486:\tlearn: 0.8755634\ttotal: 6.2s\tremaining: 6.53s\n",
      "487:\tlearn: 0.8752968\ttotal: 6.21s\tremaining: 6.51s\n",
      "488:\tlearn: 0.8749127\ttotal: 6.22s\tremaining: 6.5s\n",
      "489:\tlearn: 0.8745911\ttotal: 6.23s\tremaining: 6.49s\n",
      "490:\tlearn: 0.8740712\ttotal: 6.25s\tremaining: 6.47s\n",
      "491:\tlearn: 0.8738227\ttotal: 6.26s\tremaining: 6.46s\n",
      "492:\tlearn: 0.8731484\ttotal: 6.27s\tremaining: 6.45s\n",
      "493:\tlearn: 0.8727698\ttotal: 6.28s\tremaining: 6.43s\n",
      "494:\tlearn: 0.8724659\ttotal: 6.29s\tremaining: 6.42s\n",
      "495:\tlearn: 0.8722996\ttotal: 6.3s\tremaining: 6.41s\n",
      "496:\tlearn: 0.8717105\ttotal: 6.32s\tremaining: 6.39s\n",
      "497:\tlearn: 0.8714258\ttotal: 6.33s\tremaining: 6.38s\n",
      "498:\tlearn: 0.8711371\ttotal: 6.34s\tremaining: 6.36s\n",
      "499:\tlearn: 0.8708813\ttotal: 6.35s\tremaining: 6.35s\n",
      "500:\tlearn: 0.8707364\ttotal: 6.36s\tremaining: 6.34s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "501:\tlearn: 0.8703559\ttotal: 6.37s\tremaining: 6.32s\n",
      "502:\tlearn: 0.8699735\ttotal: 6.39s\tremaining: 6.31s\n",
      "503:\tlearn: 0.8695448\ttotal: 6.4s\tremaining: 6.3s\n",
      "504:\tlearn: 0.8692274\ttotal: 6.41s\tremaining: 6.29s\n",
      "505:\tlearn: 0.8691121\ttotal: 6.42s\tremaining: 6.27s\n",
      "506:\tlearn: 0.8688079\ttotal: 6.44s\tremaining: 6.26s\n",
      "507:\tlearn: 0.8684685\ttotal: 6.45s\tremaining: 6.25s\n",
      "508:\tlearn: 0.8681099\ttotal: 6.46s\tremaining: 6.23s\n",
      "509:\tlearn: 0.8678746\ttotal: 6.47s\tremaining: 6.22s\n",
      "510:\tlearn: 0.8675266\ttotal: 6.48s\tremaining: 6.2s\n",
      "511:\tlearn: 0.8673662\ttotal: 6.49s\tremaining: 6.19s\n",
      "512:\tlearn: 0.8670827\ttotal: 6.5s\tremaining: 6.18s\n",
      "513:\tlearn: 0.8667823\ttotal: 6.52s\tremaining: 6.16s\n",
      "514:\tlearn: 0.8666047\ttotal: 6.53s\tremaining: 6.15s\n",
      "515:\tlearn: 0.8663835\ttotal: 6.54s\tremaining: 6.14s\n",
      "516:\tlearn: 0.8662026\ttotal: 6.55s\tremaining: 6.12s\n",
      "517:\tlearn: 0.8657916\ttotal: 6.56s\tremaining: 6.11s\n",
      "518:\tlearn: 0.8656139\ttotal: 6.58s\tremaining: 6.09s\n",
      "519:\tlearn: 0.8653966\ttotal: 6.59s\tremaining: 6.08s\n",
      "520:\tlearn: 0.8651473\ttotal: 6.6s\tremaining: 6.07s\n",
      "521:\tlearn: 0.8649231\ttotal: 6.61s\tremaining: 6.06s\n",
      "522:\tlearn: 0.8647125\ttotal: 6.63s\tremaining: 6.04s\n",
      "523:\tlearn: 0.8643893\ttotal: 6.64s\tremaining: 6.03s\n",
      "524:\tlearn: 0.8640491\ttotal: 6.65s\tremaining: 6.02s\n",
      "525:\tlearn: 0.8635149\ttotal: 6.66s\tremaining: 6s\n",
      "526:\tlearn: 0.8632666\ttotal: 6.67s\tremaining: 5.99s\n",
      "527:\tlearn: 0.8627056\ttotal: 6.69s\tremaining: 5.98s\n",
      "528:\tlearn: 0.8622444\ttotal: 6.7s\tremaining: 5.96s\n",
      "529:\tlearn: 0.8621211\ttotal: 6.71s\tremaining: 5.95s\n",
      "530:\tlearn: 0.8616304\ttotal: 6.72s\tremaining: 5.94s\n",
      "531:\tlearn: 0.8613718\ttotal: 6.74s\tremaining: 5.93s\n",
      "532:\tlearn: 0.8610995\ttotal: 6.75s\tremaining: 5.91s\n",
      "533:\tlearn: 0.8607924\ttotal: 6.76s\tremaining: 5.9s\n",
      "534:\tlearn: 0.8603690\ttotal: 6.78s\tremaining: 5.89s\n",
      "535:\tlearn: 0.8600912\ttotal: 6.79s\tremaining: 5.88s\n",
      "536:\tlearn: 0.8598980\ttotal: 6.8s\tremaining: 5.86s\n",
      "537:\tlearn: 0.8596196\ttotal: 6.81s\tremaining: 5.85s\n",
      "538:\tlearn: 0.8594642\ttotal: 6.82s\tremaining: 5.84s\n",
      "539:\tlearn: 0.8587270\ttotal: 6.84s\tremaining: 5.82s\n",
      "540:\tlearn: 0.8582848\ttotal: 6.85s\tremaining: 5.81s\n",
      "541:\tlearn: 0.8579181\ttotal: 6.86s\tremaining: 5.8s\n",
      "542:\tlearn: 0.8574824\ttotal: 6.88s\tremaining: 5.79s\n",
      "543:\tlearn: 0.8572356\ttotal: 6.89s\tremaining: 5.78s\n",
      "544:\tlearn: 0.8568760\ttotal: 6.9s\tremaining: 5.76s\n",
      "545:\tlearn: 0.8565602\ttotal: 6.92s\tremaining: 5.75s\n",
      "546:\tlearn: 0.8561753\ttotal: 6.96s\tremaining: 5.76s\n",
      "547:\tlearn: 0.8558553\ttotal: 7s\tremaining: 5.77s\n",
      "548:\tlearn: 0.8554942\ttotal: 7.03s\tremaining: 5.78s\n",
      "549:\tlearn: 0.8551816\ttotal: 7.06s\tremaining: 5.78s\n",
      "550:\tlearn: 0.8549981\ttotal: 7.08s\tremaining: 5.77s\n",
      "551:\tlearn: 0.8547164\ttotal: 7.11s\tremaining: 5.77s\n",
      "552:\tlearn: 0.8543754\ttotal: 7.13s\tremaining: 5.76s\n",
      "553:\tlearn: 0.8540787\ttotal: 7.15s\tremaining: 5.75s\n",
      "554:\tlearn: 0.8538019\ttotal: 7.16s\tremaining: 5.74s\n",
      "555:\tlearn: 0.8537074\ttotal: 7.17s\tremaining: 5.73s\n",
      "556:\tlearn: 0.8533610\ttotal: 7.19s\tremaining: 5.72s\n",
      "557:\tlearn: 0.8529424\ttotal: 7.21s\tremaining: 5.71s\n",
      "558:\tlearn: 0.8524938\ttotal: 7.23s\tremaining: 5.7s\n",
      "559:\tlearn: 0.8522922\ttotal: 7.24s\tremaining: 5.69s\n",
      "560:\tlearn: 0.8520413\ttotal: 7.26s\tremaining: 5.68s\n",
      "561:\tlearn: 0.8518627\ttotal: 7.27s\tremaining: 5.67s\n",
      "562:\tlearn: 0.8516220\ttotal: 7.29s\tremaining: 5.66s\n",
      "563:\tlearn: 0.8513824\ttotal: 7.31s\tremaining: 5.65s\n",
      "564:\tlearn: 0.8508147\ttotal: 7.33s\tremaining: 5.64s\n",
      "565:\tlearn: 0.8506242\ttotal: 7.34s\tremaining: 5.63s\n",
      "566:\tlearn: 0.8501633\ttotal: 7.36s\tremaining: 5.62s\n",
      "567:\tlearn: 0.8499378\ttotal: 7.38s\tremaining: 5.61s\n",
      "568:\tlearn: 0.8496850\ttotal: 7.39s\tremaining: 5.6s\n",
      "569:\tlearn: 0.8493912\ttotal: 7.41s\tremaining: 5.59s\n",
      "570:\tlearn: 0.8490820\ttotal: 7.42s\tremaining: 5.58s\n",
      "571:\tlearn: 0.8487205\ttotal: 7.44s\tremaining: 5.57s\n",
      "572:\tlearn: 0.8485850\ttotal: 7.45s\tremaining: 5.55s\n",
      "573:\tlearn: 0.8483382\ttotal: 7.46s\tremaining: 5.54s\n",
      "574:\tlearn: 0.8480127\ttotal: 7.48s\tremaining: 5.53s\n",
      "575:\tlearn: 0.8477669\ttotal: 7.49s\tremaining: 5.51s\n",
      "576:\tlearn: 0.8476270\ttotal: 7.5s\tremaining: 5.5s\n",
      "577:\tlearn: 0.8474868\ttotal: 7.52s\tremaining: 5.49s\n",
      "578:\tlearn: 0.8471871\ttotal: 7.53s\tremaining: 5.48s\n",
      "579:\tlearn: 0.8470284\ttotal: 7.55s\tremaining: 5.46s\n",
      "580:\tlearn: 0.8465901\ttotal: 7.56s\tremaining: 5.45s\n",
      "581:\tlearn: 0.8464252\ttotal: 7.57s\tremaining: 5.44s\n",
      "582:\tlearn: 0.8460626\ttotal: 7.59s\tremaining: 5.43s\n",
      "583:\tlearn: 0.8457409\ttotal: 7.6s\tremaining: 5.41s\n",
      "584:\tlearn: 0.8455525\ttotal: 7.62s\tremaining: 5.4s\n",
      "585:\tlearn: 0.8453893\ttotal: 7.63s\tremaining: 5.39s\n",
      "586:\tlearn: 0.8449330\ttotal: 7.64s\tremaining: 5.38s\n",
      "587:\tlearn: 0.8447667\ttotal: 7.65s\tremaining: 5.36s\n",
      "588:\tlearn: 0.8443978\ttotal: 7.67s\tremaining: 5.35s\n",
      "589:\tlearn: 0.8441656\ttotal: 7.68s\tremaining: 5.34s\n",
      "590:\tlearn: 0.8439346\ttotal: 7.69s\tremaining: 5.32s\n",
      "591:\tlearn: 0.8435793\ttotal: 7.71s\tremaining: 5.31s\n",
      "592:\tlearn: 0.8433777\ttotal: 7.72s\tremaining: 5.3s\n",
      "593:\tlearn: 0.8429366\ttotal: 7.74s\tremaining: 5.29s\n",
      "594:\tlearn: 0.8427475\ttotal: 7.75s\tremaining: 5.28s\n",
      "595:\tlearn: 0.8422685\ttotal: 7.76s\tremaining: 5.26s\n",
      "596:\tlearn: 0.8418391\ttotal: 7.78s\tremaining: 5.25s\n",
      "597:\tlearn: 0.8415892\ttotal: 7.79s\tremaining: 5.24s\n",
      "598:\tlearn: 0.8412479\ttotal: 7.8s\tremaining: 5.22s\n",
      "599:\tlearn: 0.8409676\ttotal: 7.81s\tremaining: 5.21s\n",
      "600:\tlearn: 0.8406864\ttotal: 7.83s\tremaining: 5.2s\n",
      "601:\tlearn: 0.8406101\ttotal: 7.84s\tremaining: 5.18s\n",
      "602:\tlearn: 0.8403018\ttotal: 7.85s\tremaining: 5.17s\n",
      "603:\tlearn: 0.8400056\ttotal: 7.87s\tremaining: 5.16s\n",
      "604:\tlearn: 0.8397985\ttotal: 7.88s\tremaining: 5.14s\n",
      "605:\tlearn: 0.8395369\ttotal: 7.89s\tremaining: 5.13s\n",
      "606:\tlearn: 0.8392969\ttotal: 7.91s\tremaining: 5.12s\n",
      "607:\tlearn: 0.8390391\ttotal: 7.92s\tremaining: 5.11s\n",
      "608:\tlearn: 0.8387852\ttotal: 7.93s\tremaining: 5.09s\n",
      "609:\tlearn: 0.8385825\ttotal: 7.94s\tremaining: 5.08s\n",
      "610:\tlearn: 0.8383469\ttotal: 7.96s\tremaining: 5.06s\n",
      "611:\tlearn: 0.8381976\ttotal: 7.97s\tremaining: 5.05s\n",
      "612:\tlearn: 0.8379606\ttotal: 7.98s\tremaining: 5.04s\n",
      "613:\tlearn: 0.8377037\ttotal: 7.99s\tremaining: 5.02s\n",
      "614:\tlearn: 0.8374689\ttotal: 8s\tremaining: 5.01s\n",
      "615:\tlearn: 0.8372089\ttotal: 8.01s\tremaining: 5s\n",
      "616:\tlearn: 0.8367629\ttotal: 8.03s\tremaining: 4.98s\n",
      "617:\tlearn: 0.8363773\ttotal: 8.04s\tremaining: 4.97s\n",
      "618:\tlearn: 0.8360395\ttotal: 8.05s\tremaining: 4.96s\n",
      "619:\tlearn: 0.8356634\ttotal: 8.06s\tremaining: 4.94s\n",
      "620:\tlearn: 0.8354834\ttotal: 8.07s\tremaining: 4.93s\n",
      "621:\tlearn: 0.8349124\ttotal: 8.09s\tremaining: 4.91s\n",
      "622:\tlearn: 0.8347765\ttotal: 8.1s\tremaining: 4.9s\n",
      "623:\tlearn: 0.8346150\ttotal: 8.12s\tremaining: 4.89s\n",
      "624:\tlearn: 0.8343998\ttotal: 8.13s\tremaining: 4.88s\n",
      "625:\tlearn: 0.8339333\ttotal: 8.14s\tremaining: 4.86s\n",
      "626:\tlearn: 0.8337728\ttotal: 8.15s\tremaining: 4.85s\n",
      "627:\tlearn: 0.8335118\ttotal: 8.17s\tremaining: 4.84s\n",
      "628:\tlearn: 0.8332298\ttotal: 8.18s\tremaining: 4.82s\n",
      "629:\tlearn: 0.8330095\ttotal: 8.19s\tremaining: 4.81s\n",
      "630:\tlearn: 0.8327057\ttotal: 8.2s\tremaining: 4.8s\n",
      "631:\tlearn: 0.8323568\ttotal: 8.21s\tremaining: 4.78s\n",
      "632:\tlearn: 0.8318763\ttotal: 8.23s\tremaining: 4.77s\n",
      "633:\tlearn: 0.8316938\ttotal: 8.24s\tremaining: 4.75s\n",
      "634:\tlearn: 0.8312233\ttotal: 8.25s\tremaining: 4.74s\n",
      "635:\tlearn: 0.8309372\ttotal: 8.26s\tremaining: 4.73s\n",
      "636:\tlearn: 0.8307044\ttotal: 8.28s\tremaining: 4.72s\n",
      "637:\tlearn: 0.8305205\ttotal: 8.29s\tremaining: 4.7s\n",
      "638:\tlearn: 0.8303667\ttotal: 8.3s\tremaining: 4.69s\n",
      "639:\tlearn: 0.8302331\ttotal: 8.31s\tremaining: 4.67s\n",
      "640:\tlearn: 0.8298708\ttotal: 8.32s\tremaining: 4.66s\n",
      "641:\tlearn: 0.8297177\ttotal: 8.34s\tremaining: 4.65s\n",
      "642:\tlearn: 0.8294318\ttotal: 8.35s\tremaining: 4.64s\n",
      "643:\tlearn: 0.8292339\ttotal: 8.36s\tremaining: 4.62s\n",
      "644:\tlearn: 0.8290652\ttotal: 8.38s\tremaining: 4.61s\n",
      "645:\tlearn: 0.8288066\ttotal: 8.39s\tremaining: 4.6s\n",
      "646:\tlearn: 0.8286755\ttotal: 8.4s\tremaining: 4.58s\n",
      "647:\tlearn: 0.8285481\ttotal: 8.41s\tremaining: 4.57s\n",
      "648:\tlearn: 0.8283336\ttotal: 8.42s\tremaining: 4.55s\n",
      "649:\tlearn: 0.8281478\ttotal: 8.43s\tremaining: 4.54s\n",
      "650:\tlearn: 0.8279175\ttotal: 8.44s\tremaining: 4.53s\n",
      "651:\tlearn: 0.8277627\ttotal: 8.46s\tremaining: 4.51s\n",
      "652:\tlearn: 0.8274628\ttotal: 8.47s\tremaining: 4.5s\n",
      "653:\tlearn: 0.8270444\ttotal: 8.48s\tremaining: 4.49s\n",
      "654:\tlearn: 0.8268743\ttotal: 8.49s\tremaining: 4.47s\n",
      "655:\tlearn: 0.8266061\ttotal: 8.5s\tremaining: 4.46s\n",
      "656:\tlearn: 0.8263237\ttotal: 8.51s\tremaining: 4.45s\n",
      "657:\tlearn: 0.8261673\ttotal: 8.53s\tremaining: 4.43s\n",
      "658:\tlearn: 0.8259462\ttotal: 8.54s\tremaining: 4.42s\n",
      "659:\tlearn: 0.8257362\ttotal: 8.55s\tremaining: 4.4s\n",
      "660:\tlearn: 0.8255456\ttotal: 8.56s\tremaining: 4.39s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "661:\tlearn: 0.8253055\ttotal: 8.57s\tremaining: 4.38s\n",
      "662:\tlearn: 0.8251852\ttotal: 8.59s\tremaining: 4.36s\n",
      "663:\tlearn: 0.8249857\ttotal: 8.6s\tremaining: 4.35s\n",
      "664:\tlearn: 0.8247617\ttotal: 8.61s\tremaining: 4.34s\n",
      "665:\tlearn: 0.8245156\ttotal: 8.62s\tremaining: 4.32s\n",
      "666:\tlearn: 0.8241738\ttotal: 8.63s\tremaining: 4.31s\n",
      "667:\tlearn: 0.8238926\ttotal: 8.64s\tremaining: 4.29s\n",
      "668:\tlearn: 0.8236571\ttotal: 8.65s\tremaining: 4.28s\n",
      "669:\tlearn: 0.8235614\ttotal: 8.66s\tremaining: 4.27s\n",
      "670:\tlearn: 0.8233280\ttotal: 8.68s\tremaining: 4.25s\n",
      "671:\tlearn: 0.8231159\ttotal: 8.69s\tremaining: 4.24s\n",
      "672:\tlearn: 0.8227194\ttotal: 8.7s\tremaining: 4.23s\n",
      "673:\tlearn: 0.8224682\ttotal: 8.71s\tremaining: 4.21s\n",
      "674:\tlearn: 0.8222339\ttotal: 8.72s\tremaining: 4.2s\n",
      "675:\tlearn: 0.8220716\ttotal: 8.74s\tremaining: 4.19s\n",
      "676:\tlearn: 0.8219189\ttotal: 8.75s\tremaining: 4.17s\n",
      "677:\tlearn: 0.8217876\ttotal: 8.76s\tremaining: 4.16s\n",
      "678:\tlearn: 0.8215262\ttotal: 8.78s\tremaining: 4.15s\n",
      "679:\tlearn: 0.8213118\ttotal: 8.8s\tremaining: 4.14s\n",
      "680:\tlearn: 0.8207817\ttotal: 8.83s\tremaining: 4.13s\n",
      "681:\tlearn: 0.8206122\ttotal: 8.85s\tremaining: 4.13s\n",
      "682:\tlearn: 0.8203403\ttotal: 8.87s\tremaining: 4.12s\n",
      "683:\tlearn: 0.8200797\ttotal: 8.89s\tremaining: 4.11s\n",
      "684:\tlearn: 0.8198453\ttotal: 8.91s\tremaining: 4.09s\n",
      "685:\tlearn: 0.8196028\ttotal: 8.92s\tremaining: 4.08s\n",
      "686:\tlearn: 0.8192467\ttotal: 8.93s\tremaining: 4.07s\n",
      "687:\tlearn: 0.8189673\ttotal: 8.94s\tremaining: 4.06s\n",
      "688:\tlearn: 0.8186936\ttotal: 8.96s\tremaining: 4.04s\n",
      "689:\tlearn: 0.8186250\ttotal: 8.97s\tremaining: 4.03s\n",
      "690:\tlearn: 0.8184338\ttotal: 8.98s\tremaining: 4.02s\n",
      "691:\tlearn: 0.8182538\ttotal: 8.99s\tremaining: 4s\n",
      "692:\tlearn: 0.8180347\ttotal: 9.01s\tremaining: 3.99s\n",
      "693:\tlearn: 0.8177614\ttotal: 9.02s\tremaining: 3.98s\n",
      "694:\tlearn: 0.8175573\ttotal: 9.03s\tremaining: 3.96s\n",
      "695:\tlearn: 0.8174222\ttotal: 9.05s\tremaining: 3.95s\n",
      "696:\tlearn: 0.8168455\ttotal: 9.06s\tremaining: 3.94s\n",
      "697:\tlearn: 0.8165243\ttotal: 9.07s\tremaining: 3.92s\n",
      "698:\tlearn: 0.8163390\ttotal: 9.09s\tremaining: 3.91s\n",
      "699:\tlearn: 0.8161044\ttotal: 9.1s\tremaining: 3.9s\n",
      "700:\tlearn: 0.8158565\ttotal: 9.11s\tremaining: 3.88s\n",
      "701:\tlearn: 0.8154472\ttotal: 9.12s\tremaining: 3.87s\n",
      "702:\tlearn: 0.8153027\ttotal: 9.14s\tremaining: 3.86s\n",
      "703:\tlearn: 0.8150497\ttotal: 9.15s\tremaining: 3.85s\n",
      "704:\tlearn: 0.8148759\ttotal: 9.16s\tremaining: 3.83s\n",
      "705:\tlearn: 0.8146145\ttotal: 9.17s\tremaining: 3.82s\n",
      "706:\tlearn: 0.8143605\ttotal: 9.19s\tremaining: 3.81s\n",
      "707:\tlearn: 0.8141980\ttotal: 9.2s\tremaining: 3.79s\n",
      "708:\tlearn: 0.8140601\ttotal: 9.21s\tremaining: 3.78s\n",
      "709:\tlearn: 0.8138392\ttotal: 9.23s\tremaining: 3.77s\n",
      "710:\tlearn: 0.8136340\ttotal: 9.24s\tremaining: 3.75s\n",
      "711:\tlearn: 0.8133791\ttotal: 9.25s\tremaining: 3.74s\n",
      "712:\tlearn: 0.8131348\ttotal: 9.26s\tremaining: 3.73s\n",
      "713:\tlearn: 0.8129359\ttotal: 9.28s\tremaining: 3.71s\n",
      "714:\tlearn: 0.8125332\ttotal: 9.29s\tremaining: 3.7s\n",
      "715:\tlearn: 0.8122890\ttotal: 9.3s\tremaining: 3.69s\n",
      "716:\tlearn: 0.8119856\ttotal: 9.31s\tremaining: 3.68s\n",
      "717:\tlearn: 0.8116471\ttotal: 9.33s\tremaining: 3.66s\n",
      "718:\tlearn: 0.8114069\ttotal: 9.34s\tremaining: 3.65s\n",
      "719:\tlearn: 0.8111891\ttotal: 9.35s\tremaining: 3.64s\n",
      "720:\tlearn: 0.8110603\ttotal: 9.37s\tremaining: 3.62s\n",
      "721:\tlearn: 0.8107267\ttotal: 9.38s\tremaining: 3.61s\n",
      "722:\tlearn: 0.8103724\ttotal: 9.39s\tremaining: 3.6s\n",
      "723:\tlearn: 0.8101281\ttotal: 9.4s\tremaining: 3.58s\n",
      "724:\tlearn: 0.8099397\ttotal: 9.42s\tremaining: 3.57s\n",
      "725:\tlearn: 0.8097227\ttotal: 9.43s\tremaining: 3.56s\n",
      "726:\tlearn: 0.8096006\ttotal: 9.45s\tremaining: 3.55s\n",
      "727:\tlearn: 0.8094216\ttotal: 9.46s\tremaining: 3.53s\n",
      "728:\tlearn: 0.8092506\ttotal: 9.47s\tremaining: 3.52s\n",
      "729:\tlearn: 0.8090224\ttotal: 9.48s\tremaining: 3.51s\n",
      "730:\tlearn: 0.8086676\ttotal: 9.49s\tremaining: 3.49s\n",
      "731:\tlearn: 0.8085055\ttotal: 9.51s\tremaining: 3.48s\n",
      "732:\tlearn: 0.8083413\ttotal: 9.52s\tremaining: 3.47s\n",
      "733:\tlearn: 0.8080510\ttotal: 9.53s\tremaining: 3.45s\n",
      "734:\tlearn: 0.8079004\ttotal: 9.54s\tremaining: 3.44s\n",
      "735:\tlearn: 0.8076040\ttotal: 9.56s\tremaining: 3.43s\n",
      "736:\tlearn: 0.8074339\ttotal: 9.57s\tremaining: 3.42s\n",
      "737:\tlearn: 0.8073568\ttotal: 9.58s\tremaining: 3.4s\n",
      "738:\tlearn: 0.8069774\ttotal: 9.6s\tremaining: 3.39s\n",
      "739:\tlearn: 0.8068677\ttotal: 9.61s\tremaining: 3.38s\n",
      "740:\tlearn: 0.8065572\ttotal: 9.62s\tremaining: 3.36s\n",
      "741:\tlearn: 0.8064682\ttotal: 9.63s\tremaining: 3.35s\n",
      "742:\tlearn: 0.8062488\ttotal: 9.65s\tremaining: 3.34s\n",
      "743:\tlearn: 0.8059697\ttotal: 9.66s\tremaining: 3.32s\n",
      "744:\tlearn: 0.8055038\ttotal: 9.67s\tremaining: 3.31s\n",
      "745:\tlearn: 0.8052623\ttotal: 9.69s\tremaining: 3.3s\n",
      "746:\tlearn: 0.8048404\ttotal: 9.7s\tremaining: 3.29s\n",
      "747:\tlearn: 0.8046606\ttotal: 9.71s\tremaining: 3.27s\n",
      "748:\tlearn: 0.8045792\ttotal: 9.72s\tremaining: 3.26s\n",
      "749:\tlearn: 0.8041468\ttotal: 9.74s\tremaining: 3.25s\n",
      "750:\tlearn: 0.8036488\ttotal: 9.75s\tremaining: 3.23s\n",
      "751:\tlearn: 0.8034126\ttotal: 9.77s\tremaining: 3.22s\n",
      "752:\tlearn: 0.8031168\ttotal: 9.78s\tremaining: 3.21s\n",
      "753:\tlearn: 0.8029916\ttotal: 9.79s\tremaining: 3.19s\n",
      "754:\tlearn: 0.8028305\ttotal: 9.8s\tremaining: 3.18s\n",
      "755:\tlearn: 0.8025954\ttotal: 9.82s\tremaining: 3.17s\n",
      "756:\tlearn: 0.8023968\ttotal: 9.84s\tremaining: 3.16s\n",
      "757:\tlearn: 0.8021478\ttotal: 9.85s\tremaining: 3.14s\n",
      "758:\tlearn: 0.8019117\ttotal: 9.86s\tremaining: 3.13s\n",
      "759:\tlearn: 0.8016467\ttotal: 9.88s\tremaining: 3.12s\n",
      "760:\tlearn: 0.8014254\ttotal: 9.89s\tremaining: 3.1s\n",
      "761:\tlearn: 0.8011773\ttotal: 9.9s\tremaining: 3.09s\n",
      "762:\tlearn: 0.8008034\ttotal: 9.91s\tremaining: 3.08s\n",
      "763:\tlearn: 0.8005918\ttotal: 9.93s\tremaining: 3.07s\n",
      "764:\tlearn: 0.8003836\ttotal: 9.94s\tremaining: 3.05s\n",
      "765:\tlearn: 0.8000043\ttotal: 9.95s\tremaining: 3.04s\n",
      "766:\tlearn: 0.7996173\ttotal: 9.96s\tremaining: 3.03s\n",
      "767:\tlearn: 0.7994550\ttotal: 9.98s\tremaining: 3.01s\n",
      "768:\tlearn: 0.7991680\ttotal: 9.99s\tremaining: 3s\n",
      "769:\tlearn: 0.7990403\ttotal: 10s\tremaining: 2.99s\n",
      "770:\tlearn: 0.7988782\ttotal: 10s\tremaining: 2.98s\n",
      "771:\tlearn: 0.7987213\ttotal: 10s\tremaining: 2.96s\n",
      "772:\tlearn: 0.7985325\ttotal: 10s\tremaining: 2.95s\n",
      "773:\tlearn: 0.7983005\ttotal: 10.1s\tremaining: 2.94s\n",
      "774:\tlearn: 0.7982076\ttotal: 10.1s\tremaining: 2.92s\n",
      "775:\tlearn: 0.7978616\ttotal: 10.1s\tremaining: 2.91s\n",
      "776:\tlearn: 0.7975437\ttotal: 10.1s\tremaining: 2.9s\n",
      "777:\tlearn: 0.7972602\ttotal: 10.1s\tremaining: 2.88s\n",
      "778:\tlearn: 0.7971168\ttotal: 10.1s\tremaining: 2.87s\n",
      "779:\tlearn: 0.7967314\ttotal: 10.1s\tremaining: 2.86s\n",
      "780:\tlearn: 0.7964848\ttotal: 10.1s\tremaining: 2.84s\n",
      "781:\tlearn: 0.7962030\ttotal: 10.2s\tremaining: 2.83s\n",
      "782:\tlearn: 0.7960539\ttotal: 10.2s\tremaining: 2.82s\n",
      "783:\tlearn: 0.7959030\ttotal: 10.2s\tremaining: 2.81s\n",
      "784:\tlearn: 0.7956613\ttotal: 10.2s\tremaining: 2.79s\n",
      "785:\tlearn: 0.7952910\ttotal: 10.2s\tremaining: 2.78s\n",
      "786:\tlearn: 0.7951268\ttotal: 10.2s\tremaining: 2.77s\n",
      "787:\tlearn: 0.7948077\ttotal: 10.2s\tremaining: 2.75s\n",
      "788:\tlearn: 0.7945543\ttotal: 10.2s\tremaining: 2.74s\n",
      "789:\tlearn: 0.7943857\ttotal: 10.3s\tremaining: 2.73s\n",
      "790:\tlearn: 0.7941583\ttotal: 10.3s\tremaining: 2.71s\n",
      "791:\tlearn: 0.7940414\ttotal: 10.3s\tremaining: 2.7s\n",
      "792:\tlearn: 0.7938706\ttotal: 10.3s\tremaining: 2.69s\n",
      "793:\tlearn: 0.7936829\ttotal: 10.3s\tremaining: 2.67s\n",
      "794:\tlearn: 0.7934865\ttotal: 10.3s\tremaining: 2.66s\n",
      "795:\tlearn: 0.7930491\ttotal: 10.3s\tremaining: 2.65s\n",
      "796:\tlearn: 0.7928447\ttotal: 10.3s\tremaining: 2.63s\n",
      "797:\tlearn: 0.7925461\ttotal: 10.4s\tremaining: 2.62s\n",
      "798:\tlearn: 0.7923866\ttotal: 10.4s\tremaining: 2.61s\n",
      "799:\tlearn: 0.7922228\ttotal: 10.4s\tremaining: 2.6s\n",
      "800:\tlearn: 0.7920506\ttotal: 10.4s\tremaining: 2.58s\n",
      "801:\tlearn: 0.7918013\ttotal: 10.4s\tremaining: 2.57s\n",
      "802:\tlearn: 0.7916080\ttotal: 10.4s\tremaining: 2.56s\n",
      "803:\tlearn: 0.7914321\ttotal: 10.4s\tremaining: 2.54s\n",
      "804:\tlearn: 0.7911821\ttotal: 10.4s\tremaining: 2.53s\n",
      "805:\tlearn: 0.7910646\ttotal: 10.5s\tremaining: 2.52s\n",
      "806:\tlearn: 0.7907282\ttotal: 10.5s\tremaining: 2.5s\n",
      "807:\tlearn: 0.7905985\ttotal: 10.5s\tremaining: 2.49s\n",
      "808:\tlearn: 0.7904216\ttotal: 10.5s\tremaining: 2.48s\n",
      "809:\tlearn: 0.7900555\ttotal: 10.5s\tremaining: 2.47s\n",
      "810:\tlearn: 0.7898257\ttotal: 10.5s\tremaining: 2.45s\n",
      "811:\tlearn: 0.7894751\ttotal: 10.6s\tremaining: 2.44s\n",
      "812:\tlearn: 0.7893551\ttotal: 10.6s\tremaining: 2.43s\n",
      "813:\tlearn: 0.7892867\ttotal: 10.6s\tremaining: 2.42s\n",
      "814:\tlearn: 0.7888929\ttotal: 10.6s\tremaining: 2.41s\n",
      "815:\tlearn: 0.7887843\ttotal: 10.6s\tremaining: 2.4s\n",
      "816:\tlearn: 0.7885306\ttotal: 10.7s\tremaining: 2.39s\n",
      "817:\tlearn: 0.7883624\ttotal: 10.7s\tremaining: 2.38s\n",
      "818:\tlearn: 0.7881804\ttotal: 10.7s\tremaining: 2.37s\n",
      "819:\tlearn: 0.7879466\ttotal: 10.7s\tremaining: 2.36s\n",
      "820:\tlearn: 0.7877207\ttotal: 10.8s\tremaining: 2.35s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "821:\tlearn: 0.7875447\ttotal: 10.8s\tremaining: 2.33s\n",
      "822:\tlearn: 0.7871370\ttotal: 10.8s\tremaining: 2.32s\n",
      "823:\tlearn: 0.7869494\ttotal: 10.8s\tremaining: 2.31s\n",
      "824:\tlearn: 0.7866037\ttotal: 10.8s\tremaining: 2.29s\n",
      "825:\tlearn: 0.7863763\ttotal: 10.8s\tremaining: 2.28s\n",
      "826:\tlearn: 0.7860994\ttotal: 10.8s\tremaining: 2.27s\n",
      "827:\tlearn: 0.7857603\ttotal: 10.9s\tremaining: 2.25s\n",
      "828:\tlearn: 0.7856462\ttotal: 10.9s\tremaining: 2.24s\n",
      "829:\tlearn: 0.7855412\ttotal: 10.9s\tremaining: 2.23s\n",
      "830:\tlearn: 0.7853034\ttotal: 10.9s\tremaining: 2.21s\n",
      "831:\tlearn: 0.7849393\ttotal: 10.9s\tremaining: 2.2s\n",
      "832:\tlearn: 0.7845926\ttotal: 10.9s\tremaining: 2.19s\n",
      "833:\tlearn: 0.7843476\ttotal: 10.9s\tremaining: 2.18s\n",
      "834:\tlearn: 0.7840291\ttotal: 11s\tremaining: 2.17s\n",
      "835:\tlearn: 0.7838450\ttotal: 11s\tremaining: 2.16s\n",
      "836:\tlearn: 0.7835720\ttotal: 11s\tremaining: 2.15s\n",
      "837:\tlearn: 0.7834009\ttotal: 11.1s\tremaining: 2.14s\n",
      "838:\tlearn: 0.7832000\ttotal: 11.1s\tremaining: 2.13s\n",
      "839:\tlearn: 0.7829196\ttotal: 11.1s\tremaining: 2.12s\n",
      "840:\tlearn: 0.7827786\ttotal: 11.1s\tremaining: 2.1s\n",
      "841:\tlearn: 0.7825519\ttotal: 11.1s\tremaining: 2.09s\n",
      "842:\tlearn: 0.7822642\ttotal: 11.2s\tremaining: 2.08s\n",
      "843:\tlearn: 0.7821200\ttotal: 11.2s\tremaining: 2.06s\n",
      "844:\tlearn: 0.7818573\ttotal: 11.2s\tremaining: 2.05s\n",
      "845:\tlearn: 0.7816904\ttotal: 11.2s\tremaining: 2.04s\n",
      "846:\tlearn: 0.7813952\ttotal: 11.2s\tremaining: 2.02s\n",
      "847:\tlearn: 0.7812764\ttotal: 11.2s\tremaining: 2.01s\n",
      "848:\tlearn: 0.7810364\ttotal: 11.2s\tremaining: 2s\n",
      "849:\tlearn: 0.7809030\ttotal: 11.3s\tremaining: 1.99s\n",
      "850:\tlearn: 0.7807174\ttotal: 11.3s\tremaining: 1.97s\n",
      "851:\tlearn: 0.7805915\ttotal: 11.3s\tremaining: 1.96s\n",
      "852:\tlearn: 0.7802677\ttotal: 11.3s\tremaining: 1.95s\n",
      "853:\tlearn: 0.7800924\ttotal: 11.3s\tremaining: 1.93s\n",
      "854:\tlearn: 0.7798320\ttotal: 11.3s\tremaining: 1.92s\n",
      "855:\tlearn: 0.7795330\ttotal: 11.3s\tremaining: 1.91s\n",
      "856:\tlearn: 0.7792374\ttotal: 11.4s\tremaining: 1.9s\n",
      "857:\tlearn: 0.7790385\ttotal: 11.4s\tremaining: 1.88s\n",
      "858:\tlearn: 0.7788836\ttotal: 11.4s\tremaining: 1.87s\n",
      "859:\tlearn: 0.7786996\ttotal: 11.4s\tremaining: 1.86s\n",
      "860:\tlearn: 0.7783534\ttotal: 11.4s\tremaining: 1.84s\n",
      "861:\tlearn: 0.7780793\ttotal: 11.4s\tremaining: 1.83s\n",
      "862:\tlearn: 0.7779037\ttotal: 11.5s\tremaining: 1.82s\n",
      "863:\tlearn: 0.7776332\ttotal: 11.5s\tremaining: 1.8s\n",
      "864:\tlearn: 0.7775500\ttotal: 11.5s\tremaining: 1.79s\n",
      "865:\tlearn: 0.7772471\ttotal: 11.5s\tremaining: 1.78s\n",
      "866:\tlearn: 0.7771321\ttotal: 11.5s\tremaining: 1.76s\n",
      "867:\tlearn: 0.7769042\ttotal: 11.5s\tremaining: 1.75s\n",
      "868:\tlearn: 0.7767658\ttotal: 11.5s\tremaining: 1.74s\n",
      "869:\tlearn: 0.7765284\ttotal: 11.6s\tremaining: 1.73s\n",
      "870:\tlearn: 0.7764070\ttotal: 11.6s\tremaining: 1.71s\n",
      "871:\tlearn: 0.7762091\ttotal: 11.6s\tremaining: 1.7s\n",
      "872:\tlearn: 0.7759116\ttotal: 11.6s\tremaining: 1.69s\n",
      "873:\tlearn: 0.7758188\ttotal: 11.6s\tremaining: 1.67s\n",
      "874:\tlearn: 0.7754320\ttotal: 11.6s\tremaining: 1.66s\n",
      "875:\tlearn: 0.7751385\ttotal: 11.6s\tremaining: 1.65s\n",
      "876:\tlearn: 0.7748336\ttotal: 11.7s\tremaining: 1.64s\n",
      "877:\tlearn: 0.7745250\ttotal: 11.7s\tremaining: 1.62s\n",
      "878:\tlearn: 0.7742658\ttotal: 11.7s\tremaining: 1.61s\n",
      "879:\tlearn: 0.7741246\ttotal: 11.7s\tremaining: 1.6s\n",
      "880:\tlearn: 0.7739610\ttotal: 11.7s\tremaining: 1.58s\n",
      "881:\tlearn: 0.7736423\ttotal: 11.7s\tremaining: 1.57s\n",
      "882:\tlearn: 0.7734118\ttotal: 11.7s\tremaining: 1.56s\n",
      "883:\tlearn: 0.7732718\ttotal: 11.8s\tremaining: 1.54s\n",
      "884:\tlearn: 0.7731416\ttotal: 11.8s\tremaining: 1.53s\n",
      "885:\tlearn: 0.7729869\ttotal: 11.8s\tremaining: 1.52s\n",
      "886:\tlearn: 0.7728446\ttotal: 11.8s\tremaining: 1.5s\n",
      "887:\tlearn: 0.7726373\ttotal: 11.8s\tremaining: 1.49s\n",
      "888:\tlearn: 0.7725543\ttotal: 11.8s\tremaining: 1.48s\n",
      "889:\tlearn: 0.7723259\ttotal: 11.9s\tremaining: 1.47s\n",
      "890:\tlearn: 0.7721386\ttotal: 11.9s\tremaining: 1.45s\n",
      "891:\tlearn: 0.7720115\ttotal: 11.9s\tremaining: 1.44s\n",
      "892:\tlearn: 0.7716958\ttotal: 11.9s\tremaining: 1.42s\n",
      "893:\tlearn: 0.7714538\ttotal: 11.9s\tremaining: 1.41s\n",
      "894:\tlearn: 0.7712667\ttotal: 11.9s\tremaining: 1.4s\n",
      "895:\tlearn: 0.7709870\ttotal: 11.9s\tremaining: 1.38s\n",
      "896:\tlearn: 0.7707985\ttotal: 11.9s\tremaining: 1.37s\n",
      "897:\tlearn: 0.7706117\ttotal: 12s\tremaining: 1.36s\n",
      "898:\tlearn: 0.7704554\ttotal: 12s\tremaining: 1.34s\n",
      "899:\tlearn: 0.7702542\ttotal: 12s\tremaining: 1.33s\n",
      "900:\tlearn: 0.7700721\ttotal: 12s\tremaining: 1.32s\n",
      "901:\tlearn: 0.7699105\ttotal: 12s\tremaining: 1.3s\n",
      "902:\tlearn: 0.7697104\ttotal: 12s\tremaining: 1.29s\n",
      "903:\tlearn: 0.7696062\ttotal: 12s\tremaining: 1.28s\n",
      "904:\tlearn: 0.7694957\ttotal: 12s\tremaining: 1.26s\n",
      "905:\tlearn: 0.7692157\ttotal: 12.1s\tremaining: 1.25s\n",
      "906:\tlearn: 0.7690162\ttotal: 12.1s\tremaining: 1.24s\n",
      "907:\tlearn: 0.7687213\ttotal: 12.1s\tremaining: 1.22s\n",
      "908:\tlearn: 0.7685780\ttotal: 12.1s\tremaining: 1.21s\n",
      "909:\tlearn: 0.7684620\ttotal: 12.1s\tremaining: 1.2s\n",
      "910:\tlearn: 0.7682996\ttotal: 12.1s\tremaining: 1.18s\n",
      "911:\tlearn: 0.7680660\ttotal: 12.1s\tremaining: 1.17s\n",
      "912:\tlearn: 0.7679005\ttotal: 12.1s\tremaining: 1.16s\n",
      "913:\tlearn: 0.7676557\ttotal: 12.2s\tremaining: 1.14s\n",
      "914:\tlearn: 0.7675160\ttotal: 12.2s\tremaining: 1.13s\n",
      "915:\tlearn: 0.7673031\ttotal: 12.2s\tremaining: 1.12s\n",
      "916:\tlearn: 0.7669943\ttotal: 12.2s\tremaining: 1.1s\n",
      "917:\tlearn: 0.7667201\ttotal: 12.2s\tremaining: 1.09s\n",
      "918:\tlearn: 0.7665577\ttotal: 12.2s\tremaining: 1.08s\n",
      "919:\tlearn: 0.7664413\ttotal: 12.2s\tremaining: 1.06s\n",
      "920:\tlearn: 0.7662489\ttotal: 12.2s\tremaining: 1.05s\n",
      "921:\tlearn: 0.7660651\ttotal: 12.3s\tremaining: 1.04s\n",
      "922:\tlearn: 0.7660031\ttotal: 12.3s\tremaining: 1.02s\n",
      "923:\tlearn: 0.7657636\ttotal: 12.3s\tremaining: 1.01s\n",
      "924:\tlearn: 0.7654831\ttotal: 12.3s\tremaining: 997ms\n",
      "925:\tlearn: 0.7652781\ttotal: 12.3s\tremaining: 984ms\n",
      "926:\tlearn: 0.7649737\ttotal: 12.3s\tremaining: 970ms\n",
      "927:\tlearn: 0.7648920\ttotal: 12.3s\tremaining: 957ms\n",
      "928:\tlearn: 0.7645803\ttotal: 12.3s\tremaining: 944ms\n",
      "929:\tlearn: 0.7643988\ttotal: 12.4s\tremaining: 930ms\n",
      "930:\tlearn: 0.7642215\ttotal: 12.4s\tremaining: 917ms\n",
      "931:\tlearn: 0.7640242\ttotal: 12.4s\tremaining: 904ms\n",
      "932:\tlearn: 0.7637336\ttotal: 12.4s\tremaining: 890ms\n",
      "933:\tlearn: 0.7635256\ttotal: 12.4s\tremaining: 877ms\n",
      "934:\tlearn: 0.7632977\ttotal: 12.4s\tremaining: 864ms\n",
      "935:\tlearn: 0.7630057\ttotal: 12.4s\tremaining: 850ms\n",
      "936:\tlearn: 0.7626698\ttotal: 12.4s\tremaining: 837ms\n",
      "937:\tlearn: 0.7622590\ttotal: 12.5s\tremaining: 824ms\n",
      "938:\tlearn: 0.7620802\ttotal: 12.5s\tremaining: 811ms\n",
      "939:\tlearn: 0.7619447\ttotal: 12.5s\tremaining: 797ms\n",
      "940:\tlearn: 0.7617234\ttotal: 12.5s\tremaining: 784ms\n",
      "941:\tlearn: 0.7614257\ttotal: 12.5s\tremaining: 771ms\n",
      "942:\tlearn: 0.7610647\ttotal: 12.5s\tremaining: 757ms\n",
      "943:\tlearn: 0.7608285\ttotal: 12.5s\tremaining: 744ms\n",
      "944:\tlearn: 0.7605426\ttotal: 12.6s\tremaining: 731ms\n",
      "945:\tlearn: 0.7601562\ttotal: 12.6s\tremaining: 717ms\n",
      "946:\tlearn: 0.7600780\ttotal: 12.6s\tremaining: 704ms\n",
      "947:\tlearn: 0.7599366\ttotal: 12.6s\tremaining: 691ms\n",
      "948:\tlearn: 0.7597369\ttotal: 12.6s\tremaining: 677ms\n",
      "949:\tlearn: 0.7594793\ttotal: 12.6s\tremaining: 664ms\n",
      "950:\tlearn: 0.7592131\ttotal: 12.6s\tremaining: 651ms\n",
      "951:\tlearn: 0.7590162\ttotal: 12.6s\tremaining: 638ms\n",
      "952:\tlearn: 0.7587421\ttotal: 12.7s\tremaining: 624ms\n",
      "953:\tlearn: 0.7584409\ttotal: 12.7s\tremaining: 611ms\n",
      "954:\tlearn: 0.7581305\ttotal: 12.7s\tremaining: 598ms\n",
      "955:\tlearn: 0.7579715\ttotal: 12.7s\tremaining: 584ms\n",
      "956:\tlearn: 0.7578100\ttotal: 12.7s\tremaining: 571ms\n",
      "957:\tlearn: 0.7574917\ttotal: 12.7s\tremaining: 558ms\n",
      "958:\tlearn: 0.7572164\ttotal: 12.7s\tremaining: 544ms\n",
      "959:\tlearn: 0.7570979\ttotal: 12.7s\tremaining: 531ms\n",
      "960:\tlearn: 0.7568341\ttotal: 12.8s\tremaining: 518ms\n",
      "961:\tlearn: 0.7565781\ttotal: 12.8s\tremaining: 505ms\n",
      "962:\tlearn: 0.7563374\ttotal: 12.8s\tremaining: 491ms\n",
      "963:\tlearn: 0.7560677\ttotal: 12.8s\tremaining: 478ms\n",
      "964:\tlearn: 0.7559440\ttotal: 12.8s\tremaining: 465ms\n",
      "965:\tlearn: 0.7558055\ttotal: 12.8s\tremaining: 452ms\n",
      "966:\tlearn: 0.7554142\ttotal: 12.8s\tremaining: 438ms\n",
      "967:\tlearn: 0.7550724\ttotal: 12.9s\tremaining: 425ms\n",
      "968:\tlearn: 0.7549573\ttotal: 12.9s\tremaining: 412ms\n",
      "969:\tlearn: 0.7547805\ttotal: 12.9s\tremaining: 398ms\n",
      "970:\tlearn: 0.7545732\ttotal: 12.9s\tremaining: 385ms\n",
      "971:\tlearn: 0.7544117\ttotal: 12.9s\tremaining: 372ms\n",
      "972:\tlearn: 0.7542077\ttotal: 12.9s\tremaining: 358ms\n",
      "973:\tlearn: 0.7540320\ttotal: 12.9s\tremaining: 345ms\n",
      "974:\tlearn: 0.7537267\ttotal: 12.9s\tremaining: 332ms\n",
      "975:\tlearn: 0.7532573\ttotal: 13s\tremaining: 319ms\n",
      "976:\tlearn: 0.7530375\ttotal: 13s\tremaining: 305ms\n",
      "977:\tlearn: 0.7528219\ttotal: 13s\tremaining: 292ms\n",
      "978:\tlearn: 0.7526778\ttotal: 13s\tremaining: 279ms\n",
      "979:\tlearn: 0.7525228\ttotal: 13s\tremaining: 266ms\n",
      "980:\tlearn: 0.7523994\ttotal: 13s\tremaining: 252ms\n",
      "981:\tlearn: 0.7522882\ttotal: 13s\tremaining: 239ms\n",
      "982:\tlearn: 0.7521480\ttotal: 13s\tremaining: 226ms\n",
      "983:\tlearn: 0.7520157\ttotal: 13.1s\tremaining: 212ms\n",
      "984:\tlearn: 0.7517299\ttotal: 13.1s\tremaining: 199ms\n",
      "985:\tlearn: 0.7515246\ttotal: 13.1s\tremaining: 186ms\n",
      "986:\tlearn: 0.7513541\ttotal: 13.1s\tremaining: 172ms\n",
      "987:\tlearn: 0.7509510\ttotal: 13.1s\tremaining: 159ms\n",
      "988:\tlearn: 0.7508635\ttotal: 13.1s\tremaining: 146ms\n",
      "989:\tlearn: 0.7506549\ttotal: 13.1s\tremaining: 133ms\n",
      "990:\tlearn: 0.7505228\ttotal: 13.1s\tremaining: 119ms\n",
      "991:\tlearn: 0.7501602\ttotal: 13.2s\tremaining: 106ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "992:\tlearn: 0.7499589\ttotal: 13.2s\tremaining: 92.9ms\n",
      "993:\tlearn: 0.7498122\ttotal: 13.2s\tremaining: 79.6ms\n",
      "994:\tlearn: 0.7496949\ttotal: 13.2s\tremaining: 66.3ms\n",
      "995:\tlearn: 0.7493845\ttotal: 13.2s\tremaining: 53.1ms\n",
      "996:\tlearn: 0.7492224\ttotal: 13.2s\tremaining: 39.8ms\n",
      "997:\tlearn: 0.7490389\ttotal: 13.2s\tremaining: 26.5ms\n",
      "998:\tlearn: 0.7489204\ttotal: 13.2s\tremaining: 13.3ms\n",
      "999:\tlearn: 0.7486763\ttotal: 13.3s\tremaining: 0us\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.010271\n",
      "[LightGBM] [Debug] init for col-wise cost 0.000028 seconds, init for row-wise cost 0.003260 seconds\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004850 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4580\n",
      "[LightGBM] [Info] Number of data points in the train set: 6000, number of used features: 44\n",
      "[LightGBM] [Info] Start training from score -1.690106\n",
      "[LightGBM] [Info] Start training from score -1.331806\n",
      "[LightGBM] [Info] Start training from score -0.909232\n",
      "[LightGBM] [Info] Start training from score -1.906049\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 18\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 20\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 18\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 18\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 17\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 16\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 17\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 17\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 18\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 18\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 16\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 16\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 17\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 17\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 16\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 16\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 17\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 19\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 17\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 18\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 16\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 17\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 17\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 16\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 16\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 16\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 18\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 21\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 16\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 17\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 16\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 16\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 18\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 19\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 17\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 17\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 16\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 18\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 16\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 17\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 16\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 17\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 19\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 20\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 18\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 16\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 15\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 16\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 18\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 16\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n"
     ]
    }
   ],
   "source": [
    "gdbt_model = GradientBoostingClassifier()\n",
    "gdbt_model.fit(X_train,y)\n",
    "gdbt_pred = gdbt_model.predict_proba(X_test)\n",
    "\n",
    "cbt_model = cbt.CatBoostClassifier()\n",
    "cbt_model.fit(X_train,y)\n",
    "cbt_pred = cbt_model.predict_proba(X_test)\n",
    "\n",
    "lightGBM_model = LGBMClassifier(verbose=2)\n",
    "lightGBM_model.fit(X_train,y)\n",
    "lightGBM_pred = lightGBM_model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e873939f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = test[['Group']]\n",
    "prob_cols = [i for i in submit.columns if i not in ['Group']]\n",
    "for i, f in enumerate(prob_cols):\n",
    "    sub[f] = cbt_pred[:, i]\n",
    "for i in prob_cols:\n",
    "    sub[i] = sub.groupby('Group')[i].transform('mean')\n",
    "sub = sub.drop_duplicates()\n",
    "\n",
    "#sub.to_csv(r'E:\\Study\\机器学习\\wb\\submit_lightGBM.csv', index=False)\n",
    "#sub.to_csv(r'E:\\Study\\机器学习\\wb\\submit_gdbt.csv', index=False)\n",
    "sub.to_csv(r'E:\\Study\\机器学习\\wb\\submit_cbt.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e887e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0b7ead",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132f988b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
